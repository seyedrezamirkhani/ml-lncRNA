{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad257c1-6755-4632-89d5-36311b4dcc10",
   "metadata": {},
   "source": [
    "This notebook searches Google Scholar for the search term \"Machine Learning lncRNA\"\n",
    "and attempts to download any associated PDF file and check record the language associated with the file.\n",
    "\n",
    "\n",
    "The aim is to download a set of 250 papers with the associated pdf file which is in the English language.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "The search of Google Scholar takes a long time. Additionally, Google Scholar puts a limit on the number of search results that can be processed and an error is raised. The code to search and download files has been modified to stop after 3 exceptions are raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e4529-992b-46b0-91eb-c3256123a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "\n",
    "import uuid\n",
    "\n",
    "import time\n",
    "from scholarly import scholarly\n",
    "\n",
    "import PyPDF2\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200cf22-618e-462d-8b99-4783402360fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950f721-d717-4333-bff0-e9f19726ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_FOLDER = '../../../downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cc5ac6-a601-4231-8367-3b4303e5c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(file_path):\n",
    "    if file_path is None:\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            # Open the PDF file\n",
    "            with open(file_path, 'rb') as pdf_file:\n",
    "                reader = PyPDF2.PdfReader(pdf_file)\n",
    "                text = \"\"\n",
    "                \n",
    "                # Extract text from each page\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text()\n",
    "                \n",
    "                # Detect the language of the extracted text\n",
    "                if text.strip():  # Ensure there's text to analyze\n",
    "                    language = detect(text)\n",
    "                    return language\n",
    "                else:\n",
    "                    print(f\"No text found in {file_path}\")\n",
    "                    return None\n",
    "        except LangDetectException:\n",
    "            print(f\"Language detection failed for {file_path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c13889-1a4d-454e-9f67-0481d0ae8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_download_papers(query, limit, output_dir):\n",
    "    search_query = scholarly.search_pubs(query)\n",
    "    papers = []\n",
    "    counter = 0\n",
    "    error_count = 0\n",
    "    error_limit = 3\n",
    "\n",
    "    while(counter < limit):\n",
    "        try:\n",
    "            time.sleep(2)  # Introduce delay\n",
    "            paper = next(search_query)\n",
    "            paper_info = {\n",
    "                \"title\": paper.get(\"bib\", {}).get(\"title\"),\n",
    "                \"abstract\": paper.get(\"bib\", {}).get(\"abstract\"),\n",
    "                \"year\": paper.get(\"bib\", {}).get(\"pub_year\"),\n",
    "                \"url\": paper.get(\"eprint_url\", \"\"),\n",
    "                \"author_id\": paper.get(\"author_id\", []),\n",
    "                \"query\": query,\n",
    "                \"file_name\": \"\",\n",
    "                \"file_path\": None,\n",
    "                \"language\": None\n",
    "            }\n",
    "\n",
    "            # lets download the file if the url exists\n",
    "            if paper_info['url']:\n",
    "                url = paper_info['url']\n",
    "                try:\n",
    "                    # Download the file if a link is available\n",
    "                    response = requests.get(url, stream=True)\n",
    "                    content_type = response.headers.get('Content-Type', '')\n",
    "                    # Check if the content type is PDF\n",
    "                    if 'application/pdf' in content_type or mimetypes.guess_extension(content_type) == '.pdf':\n",
    "                        unique_filename = str(uuid.uuid4()) + '.pdf'\n",
    "                        file_path = os.path.join(output_dir, unique_filename)\n",
    "\n",
    "                        with open(file_path, \"wb\") as file:\n",
    "                            for chunk in response.iter_content(chunk_size=8192):\n",
    "                                file.write(chunk)\n",
    "                        \n",
    "                        print(f\"Downloaded: {file_path}\")                            \n",
    "\n",
    "                        language = detect_language(file_path=file_path)\n",
    "                        \n",
    "                        paper_info['file_name'] = unique_filename\n",
    "                        paper_info['file_path'] = file_path\n",
    "                        paper_info['language'] = language\n",
    "\n",
    "                        # the aim is to collect files that are in english\n",
    "                        if language == 'en':\n",
    "                            counter += 1\n",
    "                    else:\n",
    "                        print(f\"non-PDF content: {url}\")             \n",
    "                except Exception as e:\n",
    "                    print(f\"Error occurred while processing {url}: {e}\")                                \n",
    "            papers.append(paper_info)\n",
    "            print(paper_info)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing search : {e}\")\n",
    "            \n",
    "            if error_count < error_limit:\n",
    "                error_count += 1\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8e416-aee2-4714-80f4-9f147a1e5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = search_and_download_papers(query=\"Machine Learning lncRNA\", limit=250, output_dir=DOWNLOAD_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2ee6c-0456-4b0d-8d48-d1e902fceb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_ml_lncRNA_search_df = pd.DataFrame(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba95294-43dd-416c-9d59-dfb95c09811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_ml_lncRNA_search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c82877-0be7-4d72-a647-81c613cb0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_ml_lncRNA_search_df[large_ml_lncRNA_search_df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb1ceb-4811-41ab-b2dd-c7dfe0373739",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_ml_lncRNA_search_df.to_parquet(f'{DATA_FOLDER}large_ml_lncRNA_search_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28834b-c1d4-4b60-ae86-2943f0dbe502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
