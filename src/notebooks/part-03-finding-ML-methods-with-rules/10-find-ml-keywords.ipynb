{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c84f11-c21f-432c-bafe-be2febccf36f",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- Experiment with using a simpler empty pipeline instead of en_core_web_sm or disable unwanted pipelines, see *Disabling pipeline components* in chapter 3 of learn-spaCy project\n",
    "- Use *components with extensions* from chapter 3 of learn-spaCy project to look up the model category information e.g. training type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4028b5-0817-451a-a4a5-97139e5fd3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import PyPDF2\n",
    "import fitz  # PyMuPDF\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff926e1-2f6e-402f-ae41-35bdb400fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = '../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51370296-6d37-4310-a92d-11d0999fb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b899a7-16b4-4e27-8d1d-5049c3de355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_FOLDER = '../../../downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f6ab4c-80cd-4230-892a-0994f2b3139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_ml_lncRNA_search_df = pd.read_parquet(f'{DATA_FOLDER}large_ml_lncRNA_search_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1c80a-52b2-48db-a708-ad05ea26a784",
   "metadata": {},
   "source": [
    "Filter for files that are in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbdc192-03b4-4973-a100-c87cbd069728",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_ml_lncRNA_search_df = large_ml_lncRNA_search_df[large_ml_lncRNA_search_df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4fa79b0-de16-415c-aa30-c89ff7827288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>author_id</th>\n",
       "      <th>query</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LncMachine: a machine learning algorithm for l...</td>\n",
       "      <td>We evaluated the performance of machine learni...</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://escholarship.org/content/qt32n7m7td/qt...</td>\n",
       "      <td>[ZeGca3cAAAAJ, o3DdNZMAAAAJ, Ydo9ResAAAAJ, 4IR...</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>1fcc8c69-cc2d-48d1-9052-81b0154706cd.pdf</td>\n",
       "      <td>../../../downloads/1fcc8c69-cc2d-48d1-9052-81b...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DMFLDA: a deep learning framework for predicti...</td>\n",
       "      <td>lncRNAs and diseases, and traditional machine ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://minzeng1990.github.io/Files/TCBB-DMFLD...</td>\n",
       "      <td>[Q6b80i8AAAAJ, wicacBwAAAAJ, kERS9vUAAAAJ, O_x...</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>e1460d83-589f-45ab-93fc-8b36160efa8d.pdf</td>\n",
       "      <td>../../../downloads/e1460d83-589f-45ab-93fc-8b3...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Evaluation of deep learning in non-coding RNA ...</td>\n",
       "      <td>In this study, we review the progress of ncRNA...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://u.osu.edu/bmbl/files/2021/01/lncfinder...</td>\n",
       "      <td>[xAqx-WkAAAAJ, 2tbe1RoAAAAJ, Vt5edEkAAAAJ]</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>59adb036-a0ef-4839-ab89-4f3990b7e26e.pdf</td>\n",
       "      <td>../../../downloads/59adb036-a0ef-4839-ab89-4f3...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>A review of machine learning-based prediction ...</td>\n",
       "      <td>the subcellular localization of lncRNAs on a l...</td>\n",
       "      <td>2023</td>\n",
       "      <td>http://www.clausiuspress.com/assets/default/ar...</td>\n",
       "      <td>[, ]</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>b0d97201-c1f7-435d-9f82-0a36c76a004f.pdf</td>\n",
       "      <td>../../../downloads/b0d97201-c1f7-435d-9f82-0a3...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>LncRNA Subcellular Localization Signals–Are th...</td>\n",
       "      <td>at the 5’ end or 3’ end of lncRNA [2]. In this...</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://par.nsf.gov/servlets/purl/10538687</td>\n",
       "      <td>[Lcmc_iUAAAAJ, L8nlPxYAAAAJ, fEQEjCIAAAAJ, Wfz...</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>7889091f-b484-4e8d-bab2-0b150ba85ce3.pdf</td>\n",
       "      <td>../../../downloads/7889091f-b484-4e8d-bab2-0b1...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Mitochondrial Import of Malat1 Regulates Cardi...</td>\n",
       "      <td>machine learning in the classi cation of lncRN...</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://scholar.archive.org/work/urt26oavknafp...</td>\n",
       "      <td>[hhOh95IAAAAJ, SWozBjAAAAAJ, , X_RVrq4AAAAJ]</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>a8d9deec-c217-4bf1-86a8-c4bb8c10a6a2.pdf</td>\n",
       "      <td>../../../downloads/a8d9deec-c217-4bf1-86a8-c4b...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>Impact of sequencing technologies on long non-...</td>\n",
       "      <td>In summary, the analyzed tools use supervised ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.biorxiv.org/content/biorxiv/early/...</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>3ce36b96-ff84-4b84-9c17-f6fbdbbf1cef.pdf</td>\n",
       "      <td>../../../downloads/3ce36b96-ff84-4b84-9c17-f6f...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>Deciphering the methylation landscape in breas...</td>\n",
       "      <td>Innovative automated machine learning was empl...</td>\n",
       "      <td>2021</td>\n",
       "      <td>http://repository-empedu-rd.ekt.gr/empedu-rd/b...</td>\n",
       "      <td>[, hojAa00AAAAJ]</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>48c52af8-3a4f-40b9-91a8-dd04c8a41f1d.pdf</td>\n",
       "      <td>../../../downloads/48c52af8-3a4f-40b9-91a8-dd0...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>Machine learning models for predicting lymph n...</td>\n",
       "      <td>These analyses should be extended to the effec...</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://scholar.archive.org/work/bbbmcpqig5eyp...</td>\n",
       "      <td>[, , , , , ]</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>b55db42f-8ffb-452b-81be-a8e4270ef0a3.pdf</td>\n",
       "      <td>../../../downloads/b55db42f-8ffb-452b-81be-a8e...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>Development of New Bioinformatic Approaches fo...</td>\n",
       "      <td>(lncRNAs) in ID due to their role in gene expr...</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://tigerprints.clemson.edu/cgi/viewconten...</td>\n",
       "      <td>[ge53c0kAAAAJ]</td>\n",
       "      <td>Machine Learning lncRNA</td>\n",
       "      <td>7ea894e6-f571-456b-a4db-2c9997acf44b.pdf</td>\n",
       "      <td>../../../downloads/7ea894e6-f571-456b-a4db-2c9...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "12   LncMachine: a machine learning algorithm for l...   \n",
       "29   DMFLDA: a deep learning framework for predicti...   \n",
       "48   Evaluation of deep learning in non-coding RNA ...   \n",
       "58   A review of machine learning-based prediction ...   \n",
       "89   LncRNA Subcellular Localization Signals–Are th...   \n",
       "..                                                 ...   \n",
       "913  Mitochondrial Import of Malat1 Regulates Cardi...   \n",
       "917  Impact of sequencing technologies on long non-...   \n",
       "921  Deciphering the methylation landscape in breas...   \n",
       "928  Machine learning models for predicting lymph n...   \n",
       "929  Development of New Bioinformatic Approaches fo...   \n",
       "\n",
       "                                              abstract  year  \\\n",
       "12   We evaluated the performance of machine learni...  2021   \n",
       "29   lncRNAs and diseases, and traditional machine ...  2020   \n",
       "48   In this study, we review the progress of ncRNA...  2019   \n",
       "58   the subcellular localization of lncRNAs on a l...  2023   \n",
       "89   at the 5’ end or 3’ end of lncRNA [2]. In this...  2023   \n",
       "..                                                 ...   ...   \n",
       "913  machine learning in the classi cation of lncRN...  2020   \n",
       "917  In summary, the analyzed tools use supervised ...  2022   \n",
       "921  Innovative automated machine learning was empl...  2021   \n",
       "928  These analyses should be extended to the effec...  2020   \n",
       "929  (lncRNAs) in ID due to their role in gene expr...  2017   \n",
       "\n",
       "                                                   url  \\\n",
       "12   https://escholarship.org/content/qt32n7m7td/qt...   \n",
       "29   https://minzeng1990.github.io/Files/TCBB-DMFLD...   \n",
       "48   https://u.osu.edu/bmbl/files/2021/01/lncfinder...   \n",
       "58   http://www.clausiuspress.com/assets/default/ar...   \n",
       "89          https://par.nsf.gov/servlets/purl/10538687   \n",
       "..                                                 ...   \n",
       "913  https://scholar.archive.org/work/urt26oavknafp...   \n",
       "917  https://www.biorxiv.org/content/biorxiv/early/...   \n",
       "921  http://repository-empedu-rd.ekt.gr/empedu-rd/b...   \n",
       "928  https://scholar.archive.org/work/bbbmcpqig5eyp...   \n",
       "929  https://tigerprints.clemson.edu/cgi/viewconten...   \n",
       "\n",
       "                                             author_id  \\\n",
       "12   [ZeGca3cAAAAJ, o3DdNZMAAAAJ, Ydo9ResAAAAJ, 4IR...   \n",
       "29   [Q6b80i8AAAAJ, wicacBwAAAAJ, kERS9vUAAAAJ, O_x...   \n",
       "48          [xAqx-WkAAAAJ, 2tbe1RoAAAAJ, Vt5edEkAAAAJ]   \n",
       "58                                                [, ]   \n",
       "89   [Lcmc_iUAAAAJ, L8nlPxYAAAAJ, fEQEjCIAAAAJ, Wfz...   \n",
       "..                                                 ...   \n",
       "913       [hhOh95IAAAAJ, SWozBjAAAAAJ, , X_RVrq4AAAAJ]   \n",
       "917                                             [, , ]   \n",
       "921                                   [, hojAa00AAAAJ]   \n",
       "928                                       [, , , , , ]   \n",
       "929                                     [ge53c0kAAAAJ]   \n",
       "\n",
       "                       query                                 file_name  \\\n",
       "12   Machine Learning lncRNA  1fcc8c69-cc2d-48d1-9052-81b0154706cd.pdf   \n",
       "29   Machine Learning lncRNA  e1460d83-589f-45ab-93fc-8b36160efa8d.pdf   \n",
       "48   Machine Learning lncRNA  59adb036-a0ef-4839-ab89-4f3990b7e26e.pdf   \n",
       "58   Machine Learning lncRNA  b0d97201-c1f7-435d-9f82-0a36c76a004f.pdf   \n",
       "89   Machine Learning lncRNA  7889091f-b484-4e8d-bab2-0b150ba85ce3.pdf   \n",
       "..                       ...                                       ...   \n",
       "913  Machine Learning lncRNA  a8d9deec-c217-4bf1-86a8-c4bb8c10a6a2.pdf   \n",
       "917  Machine Learning lncRNA  3ce36b96-ff84-4b84-9c17-f6fbdbbf1cef.pdf   \n",
       "921  Machine Learning lncRNA  48c52af8-3a4f-40b9-91a8-dd04c8a41f1d.pdf   \n",
       "928  Machine Learning lncRNA  b55db42f-8ffb-452b-81be-a8e4270ef0a3.pdf   \n",
       "929  Machine Learning lncRNA  7ea894e6-f571-456b-a4db-2c9997acf44b.pdf   \n",
       "\n",
       "                                             file_path language  \n",
       "12   ../../../downloads/1fcc8c69-cc2d-48d1-9052-81b...       en  \n",
       "29   ../../../downloads/e1460d83-589f-45ab-93fc-8b3...       en  \n",
       "48   ../../../downloads/59adb036-a0ef-4839-ab89-4f3...       en  \n",
       "58   ../../../downloads/b0d97201-c1f7-435d-9f82-0a3...       en  \n",
       "89   ../../../downloads/7889091f-b484-4e8d-bab2-0b1...       en  \n",
       "..                                                 ...      ...  \n",
       "913  ../../../downloads/a8d9deec-c217-4bf1-86a8-c4b...       en  \n",
       "917  ../../../downloads/3ce36b96-ff84-4b84-9c17-f6f...       en  \n",
       "921  ../../../downloads/48c52af8-3a4f-40b9-91a8-dd0...       en  \n",
       "928  ../../../downloads/b55db42f-8ffb-452b-81be-a8e...       en  \n",
       "929  ../../../downloads/7ea894e6-f571-456b-a4db-2c9...       en  \n",
       "\n",
       "[76 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_ml_lncRNA_search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e96863-45ff-4fb3-abc9-b2af9bec3ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1d524a-861b-4408-9691-39142777bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_titles = large_ml_lncRNA_search_df['title'].values.tolist()\n",
    "paper_pdf_file_paths = large_ml_lncRNA_search_df['file_path'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ce6b1-d020-4888-8e8b-48b76b79839c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d1199d-4667-4389-8b39-192c24d133ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.entityruler.EntityRuler at 0x7a428cd5d3d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# Load the EntityRuler patterns from a file\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "ruler.from_disk(f\"{DATA_FOLDER}ml_entity_ruler_patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184a9525-b193-4a12-9630-5a63a9e7c511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine ML_METHOD\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline\n",
    "text = \"Support Vector Machine, Support Vector Machines, SVM, and S.V.M. are popular machine learning methods.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print detected entities\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"ML_METHOD\":\n",
    "        print(ent.text, ent.label_)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9efe7d3-6abd-40bd-b6b8-ace8771bc3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Support Vector Machine'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f3e0b05-cd7d-43d8-bed5-981006abd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections_from_pdf(pdf_file_path):\n",
    "    \"\"\"\n",
    "    Extracts sections from a PDF and identifies specific sections like Introduction and Discussion,\n",
    "    while ignoring References and Appendices.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with section titles as keys and their content as values.\n",
    "    \"\"\"\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_file_path)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sections = {}\n",
    "    current_section = None\n",
    "    current_text = []\n",
    "\n",
    "    # Regular expressions to identify sections\n",
    "    section_pattern = re.compile(r\"^(Introduction|Discussion|Conclusion|Methods|Results)$\", re.IGNORECASE)\n",
    "    #section_pattern = re.compile(r\"^(Introduction|Discussion|Conclusion|Methods|Results|Appendix|Appendices)$\", re.IGNORECASE)\n",
    "    ignore_pattern = re.compile(r\"^(References|Appendix|Appendices)$\", re.IGNORECASE)\n",
    "    #ignore_pattern = re.compile(r\"^(References)$\", re.IGNORECASE)\n",
    "\n",
    "    for page in doc:\n",
    "        # Extract text from the page\n",
    "        text = page.get_text(\"text\")\n",
    "\n",
    "        # Split text into lines for processing\n",
    "        lines = text.splitlines()\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Check if the line matches a section title\n",
    "            section_match = section_pattern.match(line)\n",
    "            ignore_match = ignore_pattern.match(line)\n",
    "\n",
    "            if section_match:\n",
    "                # Save the current section's text\n",
    "                if current_section and current_text:\n",
    "                    sections[current_section] = \"\\n\".join(current_text)\n",
    "\n",
    "                # Start a new section\n",
    "                current_section = section_match.group(0).capitalize()\n",
    "                current_text = []\n",
    "\n",
    "            elif ignore_match:\n",
    "                # Stop processing further sections if references or appendices are encountered\n",
    "                if current_section and current_text:\n",
    "                    sections[current_section] = \"\\n\".join(current_text)\n",
    "                current_section = None\n",
    "                current_text = []\n",
    "\n",
    "            elif current_section:\n",
    "                # Append text to the current section\n",
    "                current_text.append(line)\n",
    "\n",
    "    # Save the last section's text\n",
    "    if current_section and current_text:\n",
    "        sections[current_section] = \"\\n\".join(current_text)\n",
    "\n",
    "    doc.close()\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ad2ad6-b798-4db6-8f57-b7fdd2912557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_file(pdf_file_path):    \n",
    "    search_results = dict()\n",
    "    # Extract text from PDF\n",
    "    with open(pdf_file_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page_num, page in enumerate(pdf_reader.pages):\n",
    "            # Extract text from the page\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                # Use spaCy to process the text\n",
    "                doc = nlp(text)\n",
    "                \n",
    "                # Detect entities\n",
    "                for ent in doc.ents:\n",
    "                    if ent.label_ == \"ML_METHOD\":\n",
    "                        if ent.text in search_results:\n",
    "                            search_results[ent.text].append(page_num + 1)  # Store page number (1-indexed)\n",
    "                        else:\n",
    "                            search_results[ent.text] = [page_num + 1]  # Store page number (1-indexed)\n",
    "    \n",
    "    # Display search results\n",
    "    for term, pages in search_results.items():\n",
    "        if pages:\n",
    "            print(f\"'{term}' found on page(s): {set(pages)}\")\n",
    "        #else:\n",
    "        #    print(f\"'{term}' not found in the document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f46406-039a-49eb-a6c6-5a871a8df8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "processing: LncMachine: a machine learning algorithm for long noncoding RNA annotation in plants\n",
      "--------------------------------------------------------------------------------\n",
      "'Random Forest' found on page(s): {1, 3, 4, 9}\n",
      "'Support Vector Machine' found on page(s): {2, 4, 5}\n",
      "'SVM' found on page(s): {2, 4, 5}\n",
      "'Logistic Regression' found on page(s): {2, 6}\n",
      "'decision tree' found on page(s): {2}\n",
      "'Random Forests' found on page(s): {2}\n",
      "'boosting' found on page(s): {2}\n",
      "'AdaBoost' found on page(s): {3, 4}\n",
      "'Neural Networks' found on page(s): {9, 7}\n",
      "'random forests' found on page(s): {9}\n",
      "'support vector machine' found on page(s): {10}\n",
      "'GMM' found on page(s): {10}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for paper_title, pdf_file_path in zip(paper_titles, paper_pdf_file_paths):\n",
    "    print('-'*80)\n",
    "    print(f'processing: {paper_title}')\n",
    "    print('-'*80)\n",
    "    search_in_file(pdf_file_path=pdf_file_path)\n",
    "    print('-'*80)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92d8156e-2ee5-4379-a722-a33ed3e2515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "processing: LncMachine: a machine learning algorithm for long noncoding RNA annotation in plants\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "{'Introduction': 'With current advances in high-throughput sequencing tech-\\nnologies, a vast number of transcripts have been experimen-\\ntally determined for a plethora of different species, including a\\nnumber of plants, animals, insects, and microbes (Szymański\\nand Barciszewski 2002; Claverie 2005; Mercer et al. 2011;\\nCagirici et al. 2017; IWGSC 2018). Transcriptomic and geno-\\nmic studies have revealed that although the lengths of many of\\nthese transcripts are greater than 200 nucleotides, the majority\\ndo not code for functional proteins (Pennisi 2012; Budak et al.\\n2020). Such transcripts have been defined as long noncoding\\nRNAs (lncRNAs). Initially, the lack of evidence for their func-\\ntion and evolutionary conservation raised concerns about the\\npotential importance of lncRNAs (Struhl 2007). However,\\nmany of these concerns have now been experimentally ad-\\ndressed by the functional characterization of lncRNAs in\\nmany important biological processes (i.e., COOLAIR/\\nCOLDAIR) (Heo and Sung 2011). Studies in the last decade\\nhave revealed diverse regulatory functions, including biolog-\\nically significant interactions such as between lncRNA:RNA\\nand lncRNA:chromatin (Chekanova 2015) and involvement\\nin several important biological processes, such as vernaliza-\\ntion (Swiezewski et al. 2009), photo morphogenesis (Wang\\net al. 2014), reproduction (Ding et al. 2012), nodulation\\n(Campalans 2004), and environmental stress adaptation (Liu\\net al. 2012).\\nFurthermore, lncRNAs appear to exhibit tissue-specific ex-\\npression and functional conservation (Cabili et al. 2011;\\nUlitsky et al. 2011). Although sequence conservation almost\\nalways accounts for the functionality of a sequence, vice versa\\nis not always true (Shannon et al. 2003). Instead of full-length\\nsequence conservation, lncRNAs may have conserved small\\nbinding sites at the structural level to maintain functional\\n* Hikmet Budak\\nhikmet.budak@icloud.com\\n1\\nUS Department of Agriculture - Agricultural Research Service, Crop\\nImprovement Genetics Research Unit, Western Regional Research\\nCenter, 800 Buchanan St, Albany, CA 94710, USA\\n2\\nFaculty of Engineering and Natural Sciences, Sabanci University,\\nTuzla, Istanbul, Turkey\\n3\\nETSI Informatica, University of Malaga Andalucía Tech.,\\n29071 Malaga, Spain\\n4\\nMontana BioAgriculture Inc., Missoula, MT, USA\\nFunctional & Integrative Genomics\\nhttps://doi.org/10.1007/s10142-021-00769-w\\ninteractions with proteins or other DNA/RNAs (Militti et al.\\n2014). Therefore, the understanding of the diverse functions\\nof lncRNAs has the potential to provide insights into the dif-\\nferent constraints that also drive conservation of other RNA\\nclasses, such as messenger RNAs (mRNAs) and micro RNAs\\n(miRNAs) (Hezroni et al. 2015).\\nDespite their importance, computational identification of\\nlncRNA during genome annotation is challenging. To distin-\\nguish lncRNAs from classes of small noncoding RNAs, such\\nas miRNAs, the size of the transcript can be used. But dis-\\ncrimination based on length is not sufficient for identification:\\nfor example, both lncRNAs and mRNAs are long and share\\nsimilar splicing and poly-A tailed structures, and in this case,\\nother discriminants such as structural and functional features\\nneed to be used (Ulitsky and Bartel 2013). Additionally,\\nlncRNA transcripts cannot be identified solely through ho-\\nmology, as the sequences are less conserved between species\\nthan protein-coding genes (Pang et al. 2006), and the presence\\nof open reading frames in lncRNAs adds another layer of\\ncomplexity. Another challenge is the growing evidence sug-\\ngesting that some lncRNAs may not be noncoding but in fact\\ncode for short functional peptides. The best known example is\\nthe lncRNA known as early nodulin 40 (ENOD40)\\n(Campalans 2004), whose conserved nucleotide sequence at\\nthe 5′ end encodes two short peptides with lengths of 12 and\\n24 amino acids (Rohrig et al. 2002). Proteogenomic and mass\\nspectrometry have also been carried out to identify peptides\\nusing small ORFs (Andrews and Rothnagel 2014; Zhu et al.\\n2018).\\nIn recent years, several predictive tools have been devel-\\noped to distinguish between lncRNAs and coding RNAs\\nusing a range of different features and algorithms. The most\\npopular of these tools are also among the most accurate and\\ninformative: Coding Potential Calculator (CPC) (Kong et al.\\n2007), Coding Noncoding Index (CNCI) (Sun et al. 2013),\\nand Coding Potential Assessment Tool (CPAT) (Wang et al.\\n2013).\\nCPC uses a Support Vector Machine (SVM) algorithm\\nwith a standard radial basis function kernel to differentiate\\ncoding RNAs from ncRNAs based on both the extend and\\nquality of the ORFs and the evidence of sequence similarity\\nto proteins (Kong et al. 2007). In 2017, the CPC algorithm\\nwas updated to an alignment-free CPC2 (Kang et al. 2017),\\nwhich has increased the speed and accuracy of identification.\\nAs an alignment-free tool, CPC2 has become species neutral\\nthat does not require training for different species. Selected\\nfeatures were evolved in CPC2 to include ORF length, ORF\\nintegrity, isoelectric point, and Fickett score. Fickett score was\\nadapted from CPAT and refers to the asymmetrical distribu-\\ntion of each base favored in a sequence (Wang et al. 2013).\\nAnother algorithm, CPAT, evaluates coding potential\\nusing an alignment-free Logistic Regression model (Wang\\net al. 2013). Its features include ORF length, Fickett score,\\nand hexamer score. Hexamer score captures the score for co-\\ndon usage bias of adjacent amino acids in a sequence (Wang\\net al. 2013). CPAT has an advantage over CPC2 as it allows\\nusers to create a model with their own data.\\nIn comparison, CNCI is an alignment-free tool using SVM\\nwith a radial basis function kernel. It differentiates coding\\nRNAs and ncRNAs based on the intrinsic composition of\\nthe sequence (Sun et al. 2013). Similar to hexamer score in\\nCPAT, CNCI estimates the codon bias using unequal distri-\\nbution of adjoining nucleotide triplets (ANTs) via a sliding\\nwindow approach. The most likely coding domain sequence\\n(MLCDS) is selected after scanning each sequence six times\\nwithin each potential reading frame. Although this quantity\\nshows similarities with the hexamer score, the ANT approach\\nperforms a more comprehensive downstream analysis to in-\\nclude the classification of partial transcripts (Han et al. 2016).\\nCNCI was later upgraded to CNIT (Coding-Noncoding\\nIdentifying Tool) to provide faster and more accurate evalua-\\ntion of sequences using the same features (Guo et al. 2019).\\nThere are several other, but less popular lncRNA prediction\\ntools, which use different prediction models and feature sets.\\nSome of these include PLEK (Li et al. 2014), BASiNET (Ito\\net al. 2018), LncRNA-ID (Achawanantakun et al. 2015), and\\nDeepLNC (Tripathi et al. 2016). In short, PLEK facilitates\\nSupport Vector Machine using k-mer-based features to distin-\\nguish lncRNAs from coding RNAs (Li et al. 2014). BASiNET\\nuses decision tree algorithms trained with alignment-free fea-\\ntures (Ito et al. 2018). In comparison, DeepLNC facilitates\\ndeep learning (Tripathi et al. 2016), where LncRNA-ID uses\\nRandom Forests (Achawanantakun et al. 2015). Some tools\\neven construct an ensemble of models such as gradient\\nboosting and Random Forests for the prediction of plant\\nlncRNAs (Simopoulos et al. 2018).\\nAlthough current computational methods have yielded en-\\ncouraging results, certain limitations are yet to be overcome.\\nPredictions are highly dependent on training data, and while\\nmany tools aim to achieve high overall accuracy across sev-\\neral species, some focus on a narrow set of species. Recent\\nstudies have shown that species-specific predictions are opti-\\nmally obtained from training data of the same or a closely\\nrelated species (Singh et al. 2017). Singh et al. showed that\\nPLncPRO, a model built specifically for monocots, achieved\\nhigher accuracy for lncRNA prediction when applied to\\nmonocots, rather than dicots and vice versa.\\nWe developed a lncRNA prediction model, LncMachine,\\nfor crop plants and analyzed its performance for a wide range\\nof crop species, including wheat. Wheat is a major crop across\\nthe globe, ranking second in human consumption worldwide\\n(FAO 2019). To accurately identify both lncRNA transcripts\\nand coding transcripts, we developed an alignment-free pre-\\ndiction workflow that includes several machine learning algo-\\nrithms, which users can train for their species of interest. We\\nevaluated several features included in other studies and\\nFunct Integr Genomics\\nperformed feature selection algorithms to extract the best set\\nof features to distinguish coding and noncoding se-\\nquences. Using this feature set and comprehensive train-\\ning data, we first obtained 10-fold cross-validation ac-\\ncuracies for nine different algorithms, including Support\\nVector Machines, Logistic Regressions, and Random\\nForests. We then compared the prediction accuracies\\nfor two independent wheat transcript datasets for hexa-\\nploid and tetraploid wheat species, as well as for the\\nplant lncRNAs that are available at the GreeNC data-\\nbase. Last, we included the comparison of prediction\\naccuracies using the test data provided in the CPC2,\\nCPAT, and CNIT tools to show that the LncMachine\\naccuracies are not biased for a specific dataset.\\nMaterial and methods\\nDatasets\\nTraining datasets were collected from two databases: lncRNA\\nsequences from CANTATAdb v2 (Szcześniak et al. 2019)\\nand mRNA sequences from Ensembl Plants (v37).\\nCANTATAdb v2 contained lncRNAs for a wide range of\\nplant species, and these lncRNAs were based on genome as-\\nsemblies deposited in Ensembl Plants v37. We selected\\nlncRNAs from monocotyledons and eudicotyledons,\\nwhich had corresponding cDNAs deposited in Ensembl\\nPlants (v37). Sequences with >90% N stretches and\\n<200 bp in length were removed. Redundant sequences\\nhaving a sequence identity of at least 90% were also\\nremoved using CD-HIT (Fu et al. 2012) at its default\\nsettings. After filtering, an equal number of cDNAs and\\nlncRNAs were randomly selected for each species. A\\ntotal of 90,104 lncRNA sequences and 90,104 cDNA\\nsequences were included in the training dataset.\\nTest datasets included (1) lncRNAs from monocotyledons\\nand eudicotyledons deposited at GreeNC database\\n(Gallart et al. 2016), (2) an equal number of lncRNAs\\nfrom IWGSC wheat RefSeq v1.0 annotation and high-\\nconfidence CDSs from IWGSC wheat RefSeq v1.1 an-\\nnotation (IWGSC 2018) available through https://wheat-\\nurgi.versailles.inra.fr/Seq-Repository/Annotations, (3) an\\nequal number of lncRNAs and high-confidence CDSs\\nof tetraploid wheat (Svevo) (Maccaferri et al. 2019)\\navailable through https://www.interomics.eu/durum-\\nwheat-genome, as well as at GrainGenes (https://wheat.\\npw.usda.gov) (Blake et al. 2019), and (3) the datasets\\nused for testing in CPC2 (Kang et al. 2017), CPAT\\n(Wang et al. 2013), and CNIT (Guo et al. 2019).\\nThese datasets were used for comparisons of accuracies\\nindependent of the datasets chosen.\\nFeature extraction\\nInitially, we extracted 93 features based on sequence intrinsic\\nproperties (File S1) which later were subject to feature selec-\\ntion. The initial features were composed of the following:\\n1\\nORF length\\n2\\nORF coverage\\n3\\nSequence length\\n4\\nGC%\\n5–8\\nk-mer (k=1) frequencies; monomer frequencies of the\\nfour nucleotides\\n9–24\\nk-mer (k=2) frequencies; dimer frequencies of the four\\nnucleotides\\n25–88\\nk-mer (k=3) frequencies; trimer frequencies of the\\nfour nucleotides\\n89\\nFickett score from full length sequence\\n90\\nFickett score from CDSs\\n91\\nHexamer score\\n92\\nORF integrity\\n93\\nIsoelectric point\\nTo remove irrelevant and collinear features, we applied\\nseveral feature selection methodologies available through py-\\nthon scikit-learn package (Pedregosa et al. 2011). These in-\\ncluded the following:\\n–\\nVariance threshold\\n–\\nUnivariate feature selection with ANOVA F-test\\n–\\nRandom Forest Classifier\\n–\\nRecursive feature elimination\\n–\\nLasso regularization\\n–\\nPearson correlation\\nEach methodology provided a list of best features, includ-\\ning collinear features. For feature selections, collinearity was\\nreduced by Pearson pairwise correlation of the best features.\\nModel construction and evaluation\\nLncMachine can build prediction models using several ma-\\nchine learning algorithms although the default was set to\\nRandom Forest. The script was provided in supplementary\\nfiles (File S2) and available at GitHub at https://github.com/\\nhbusra/lncMachine.git. Prediction models were built\\nusing nine machine learning algorithms from the python\\nscikit-learn package: (1) LogisticRegression, (2)\\nRandomForest, (3) Multilayer Perceptron (NeuralNet), (4)\\nNearestNeighbors, (5) DecisionTree, (6) Gaussian Naïve\\nBayes (NaiveBayes), (7) AdaBoost, (8) Quadric\\nDiscriminant Analysis (QDA), and (9) Support Vector\\nMachines with linear kernel (LinearSVM). Training accura-\\ncies were calculated by a 10-fold cross-validation. Using the\\nFunct Integr Genomics\\nStratifiedKFold function of the scikit-learn package, training\\ndata were split into 10 different training/test sets. For each\\ntraining/test set, the prediction accuracies for prediction\\nmodels were calculated using the different feature sets sug-\\ngested for each algorithm. Training performance was assessed\\nby the mean and the standard deviations of the accuracy\\nscores. Due to their computational cost, Support Vector\\nMachine (SVM) algorithms were not included for further\\nanalyses after cross-validation (Table 1).\\nTesting of the prediction models on several plant datasets\\nwas then completed. The prediction performance was evalu-\\nated based on statistic metrics: accuracy (ACC), precision\\n(PRE), sensitivity/recall (SN), specificity (SP), and F-score\\n(Powers 2007). These were defined as follows:\\nAccuracy ¼\\nTP þ TN\\nTP þ TN þ FP þ FN\\nPrecision ¼\\nTP\\nTP þ FP\\nSensitivity ¼\\nTP\\nTP þ FN\\nSpecificity ¼\\nTN\\nTN þ FP\\nFscore ¼ 2 \\x02 Precision \\x02 Sensitivity\\nPrecision þ Sensitivity\\nTP\\ntrue positive\\nTN\\ntrue negative\\nFP\\nfalse positive\\nFN\\nfalse negative\\nAdditional performance assessments were performed\\nthrough plotting the Receiver Operating Characteristic\\n(ROC) curve for visualization and calculating the respective\\nArea Under the Curve (AUC) score from the ROC curve\\n(Bradley 1997).\\nTo compare the prediction performance of the LncMachine\\nagainst other tools, CPC2, CPAT, and CNIT were utilized. All\\nthree tools were updated recently and have been considered\\namong the most popular coding prediction tools. CPC2 is a\\nspecies-neutral tool that does not provide a training option for\\ndifferent species; therefore, it was run at its default settings\\nwithout training. CNIT was run in plant mode using 20\\nthreads. CPAT was trained with the same training data used\\nin the current study. The cutoff for the identification of coding\\nand noncoding transcripts was determined as described in its\\nmanual (Wang et al. 2013).', 'Results': 'Experimental setup and model construction\\nUsing a set of publicly available lncRNA and mRNA se-\\nquences for 18 plant species, we constructed a plant-based\\nlncRNA prediction tool, LncMachine, by evaluating the per-\\nformance of eight machine learning algorithms and selecting\\nthe best features. For a total of 93 sequence intrinsic features,\\nwe assessed five feature selection methodologies: Lasso,\\nRandom Forest, recursive feature elimination, variance thresh-\\nold, and univariate feature selection, all followed by Pearson\\npairwise correlation in addition to elimination of features by\\nPearson correlation alone (Table S1). After 10-fold cross-val-\\nidations, the feature set was selected by variance threshold\\nfollowed by Pearson correlation resulted in the highest accu-\\nracy and AUC score of ROC (Area Under the Receiver\\nOperating Characteristics) (Bradley 1997) for the Random\\nForest Classifier (Table S1). Random Forest Classifier and\\nthe features selected by variance threshold followed by\\nPearson correlation were selected for further analysis.\\nFirst, we applied a variance threshold to select features that\\nshowed more than 80% of variance. Variance scores varied\\nbetween 0 and 21,496,995 among 93 features. We selected the\\ntop ranking features with a score of at least 4. This highlighted\\n15 features: sequence length, ORF length, ORF coverage, GC\\ncontent, T content, A content, C content, G content, CG con-\\ntent, GC content, isoelectric point, TT content, AA content,\\nAT content, and TA content. Ranking of the features was\\nprovided in the Supplementary Table S2. Later, we applied\\nPearson pairwise correlation and selected only the highest\\nscoring features based on correlation coefficient. The final\\nset of features were sequence length, ORF length, GC content\\n(GC%), and isoelectric point (pI) (Table S2). The three fea-\\ntures except pI score were slightly higher in coding sequences\\non average, whereas pI score showed a similar distribution\\namong coding and noncoding sequences but slightly higher\\namong noncoding sequences on average (Fig. 1). Figure 2\\nTable 1\\nPerformance of prediction models using training data with a\\n10-fold cross-validation\\nAlgorithm\\nTraining accuracy (%)\\nStd (%)\\nRandomForest\\n94.09\\n± 0.18\\nAdaBoost\\n93.62\\n± 0.16\\nNearestNeighbors\\n93.40\\n± 0.16\\nNeuralNet\\n93.39\\n± 0.30\\nLinearSVM\\n91.85\\n*NA\\nLogisticRegression\\n91.69\\n± 0.20\\nDecisionTree\\n90.86\\n± 0.23\\nQDA\\n88.10\\n± 0.44\\nNaiveBayes\\n87.38\\n± 0.28\\n*NA: not available because Support Vector Machine (SVM) with linear\\nkernel was only run at 1-fold due to its computational cost\\nFunct Integr Genomics\\nshows these three major features (sequence length, ORF\\nlength, and GC%) in three-dimensional space to assess the\\nseparation of coding and noncoding sequences based on the\\nfeatures selected. Our results showed that sequence length and\\nORF length have high separation power for coding and non-\\ncoding transcripts as even the largest noncoding sequences\\ntend to contain small ORFs. Table 1 shows 10-fold cross-\\nvalidation accuracies of the nine machine learning algorithms\\nusing these four features. All of the algorithms resulted in over\\n87% cross-validation accuracy (Table 1), indicating a good fit\\nof the selected features in the prediction models. Given that\\nSupport Vector Machine (SVM) algorithm with linear kernel\\nwas not among the top performing algorithms, cross-\\nvalidation was only performed by 1-fold due to the computa-\\ntional cost of SVM algorithms. Our results showed that\\nLncMachine performs best with the RandomForest algorithm\\non the training data.\\nPerformance evaluation against other plant datasets\\nWe evaluated the performance of machine learning models on\\nlncRNAs based on sensitivity in 6 plant species from the\\nGreeNC database (Table 2). Our results showed that some\\nalgorithms perform very poorly on certain species. For exam-\\nple, lncRNAs of Oryza sativa Japonica were identified with\\nonly a range of 13–30 % sensitivity by five of the algorithms,\\nFig. 1 The density distribution of the selected features to build the prediction model for coding (orange) and noncoding (blue) sequences. (a) Sequence\\nlength, (b) ORF length, (c) pI score, and (d) GC content\\nFig. 2 The three-dimensional plot\\nof the three features: sequence\\nlength, ORF length, and GC %,\\non coding (orange) and noncod-\\ning (blue) sequences\\nFunct Integr Genomics\\nwhereas QDA and Naïve Bayes provided a 99% sensitivity.\\nInterestingly, among all nine algorithms, QDA and Naïve\\nBayes provided >96% sensitivity for all of the species.\\nThese results suggest that QDA and Naïve Bayes algorithms\\nare better suited for the identification of lncRNAs for a wide\\nrange of plant species.\\nAdditionally, the prediction models with QDA, Naïve\\nBayes, and Logistic Regression outperformed the three most\\npopular tools, CPC2, CPAT, and CNIT, for all of the species\\ntested from the GreeNC database. Among the popular tools,\\nCPC2 predicts lncRNAs with a sensitivity ranged between 77\\nand 93%, CPAT between 41 and 75%, and CNIT between 43\\nand 63%. It was interesting to observe that although CNIT and\\nCPAT were trained specifically for plants (i.e., in contrast to\\nCPC2), they provided the lowest sensitivities for identifying\\nplants lncRNAs.\\nWe also evaluated the prediction performances on two real-\\nlife case studies: hexaploid and tetraploid wheat datasets. An\\nequal number of lncRNAs and high-confidence CDS se-\\nquences were retrieved for both hexaploid (Chinese Spring)\\nand tetraploid (Svevo) wheats (Table 3). For the full set of\\ncoding and noncoding sequences of the two wheat species,\\nall nine algorithms provided >92% accuracy. Overall, our de-\\nfault RandomForest model outperformed all the remaining\\ntools and algorithms for the wheat datasets with 98.65% and\\n99.25% accuracies for hexaploid and tetraploid wheats, re-\\nspectively (Fig. 3 and Table 4). CPC2, CPAT, and CNIT\\nprovided accuracies >94%. For the wheat species, CPAT per-\\nformed better than both CPC2 and CNIT.\\nThese results show that even when the same algorithm is\\nused, different parameters, platforms, feature sets, and training\\ndata can affect prediction accuracies. For example, CNIT,\\nwhich uses LogisticRegression, and LncMachine, which uses\\nLogisticRegression, showed drastic differences in the predic-\\ntion accuracies for various test datasets. Across the test\\ndatasets, LncMachine with LogisticRegression outperformed\\nCNIT (96.58% vs 98.06% for hexaploid wheat; 97.77% vs\\n97.43% for tetraploid wheat). There was a larger difference\\nin the prediction of GreeNC plant lncRNAs, where\\nLncMachine with LogisticRegression provided an average\\nof 91.44% accuracy as opposed to an average of 50.59% from\\nCNIT. Since CNIT was run in plants mode, our results suggest\\nthat its prediction capability is highly dependent on the dataset\\nused. Interestingly, CPC2, which was by default trained on\\nhuman data, provided better prediction accuracies than CNIT\\nfor both wheat datasets and GreeNC lncRNAs (Table 2 and\\nTable 4).\\nPerformance evaluation against CPC2, CPAT, and\\nCNIT test datasets\\nTo prevent any bias introduced by the selected datasets and to\\ntest species other than plants, we used the test datasets provid-\\ned by CPC2, CPAT, and CNIT for comparison of prediction\\naccuracies. It is important to note that the datasets provided by\\nthese tools are mostly unbalanced datasets, which might intro-\\nduce a bias to prediction accuracies in the case when the pre-\\ndiction model favors either coding or noncoding sequences.\\nTest datasets of CPC2 and CPAT were mostly non-plant spe-\\ncies. However, although our training data only included plant\\nsequences, the LncMachine with LinearSVM performed\\n93.59% (±2) accuracy for non-plant datasets (Table S3). The\\nLncMachine with LogisticRegression was also shown to be\\nefficient at identifying non-plant coding and noncoding\\nTable 2 Performance comparison\\nof prediction models on GreeNC\\nlncRNAs in terms of sensitivity\\nModel\\nGreeNC (lncRNAs)\\nArabidopsis\\nthaliana\\nBrachypodium\\ndistachyon\\nOryza sativa\\nJaponica\\nSorghum\\nbicolor\\nTriticum\\naestivum\\nZea\\nmays\\nQDA\\n99.14\\n98.30\\n99.27\\n98.11\\n96.65\\n99.65\\nNearestNeighbors\\n63.56\\n74.82\\n27.06\\n74.63\\n82.01\\n69.71\\nDecisionTree\\n58.58\\n68.46\\n29.69\\n66.69\\n76.07\\n66.64\\nRandomForest\\n61.24\\n74.70\\n26.98\\n72.80\\n80.79\\n70.31\\nNeuralNet\\n44.78\\n48.14\\n13.40\\n44.18\\n54.20\\n55.09\\nAdaBoost\\n60.44\\n65.20\\n25.70\\n64.13\\n74.10\\n66.11\\nNaiveBayes\\n98.80\\n98.05\\n99.10\\n97.83\\n96.25\\n99.60\\nLogisticRegression\\n87.30\\n93.02\\n87.89\\n92.44\\n94.43\\n93.53\\nLinearSVM\\n74.57\\n85.24\\n66.64\\n84.98\\n90.35\\n83.34\\nOther tools\\nCPC2\\n80.46\\n88.76\\n77.42\\n88.60\\n93.19\\n88.57\\nCPAT\\n73.50\\n61.80\\n41.47\\n58.76\\n75.36\\n70.12\\nCNIT\\n46.86\\n50.56\\n51.81\\n47.38\\n43.95\\n62.96\\nHighest accuracy scores for each species were italicized\\nFunct Integr Genomics\\nsequences, with an average accuracy of 93.40 % (±2) and an\\naverage F1-score of 0.92 (Table S3). The LncMachine with its\\ndefault RandomForest algorithm provided very similar re-\\nsults, with an average accuracy of 92.67% (±3) and an average\\nF1-score of 0.91. These results suggest that LncMachine\\nwould also work well for non-plant species, such as human\\nand mouse.\\nCNIT, on the other hand, provided several plant coding and\\nnoncoding sequences for the test set. These plant datasets were\\nunbalanced, such that there were five lncRNA sequences for\\nSorghum bicolor and 39,045 coding sequences (Table S3).\\nBased on the CNIT plant test datasets, LncMachine with\\nNeural Networks outperformed all the algorithms and the\\ntools CPAT, CPC2, and CNIT in terms of specificity and\\naccuracy on average. Sensitivity was >0.996 on average for\\nthe LncMachine with Logistic Regression and with\\nLinearSVM and CPC2. However, CPAT provided a better\\nF1 score (0.44 on average as opposed to 0.41 of\\nLncMachine with Neural Networks). It should be noted that\\nthe low number of lncRNAs available for most of the plant\\nspecies in CNIT datasets may have resulted in unreliable F1\\nscores. For the species with more than 2500 lncRNA se-\\nquences in their test sets, F1 scores should be considered more\\naccurate and reliable (Table S3). Overall, our results suggest\\nthat there is not any single solution that can fit all the datasets\\navailable. The users have the responsibility to select the best\\nfitting algorithm for their specific study.\\nAdditional application\\nAlthough our main purpose was to develop a lncRNA predic-\\ntion tool specifically for crop plants, LncMachine can be mod-\\nified to be used of any kind of species. When FASTA files for\\ncoding and noncoding sequences are provided by a user,\\nLncMachine extracts features to distinguish lncRNAs from\\nmRNAs and performs prediction of the coding potential of\\nthe sequences provided. Otherwise, if a features file in CSV\\nformat is provided, this new tool can be run to train a specific\\nmodel other than lncRNA prediction using several machine\\nlearning algorithms which can be subsequently used for pre-\\ndiction of the test sets. The required columns for training a\\nprediction model include “class” and “features” as separate\\ncolumns. The samples can be specified as “readID” in the\\nCSV file.', 'Discussion': 'Genome annotation can be an arduous task, particularly when\\ndistinguishing coding sequences from lncRNAs which\\nTable 3 Description of datasets\\nused in training and validation of\\nthe wheat lncRNA prediction\\nmodel\\nDataset\\nSource\\nReference\\n# of mRNA\\n# of lncRNA\\nChinese Spring\\nHexaploid wheat\\nIWGSC et al. (2018)\\n87,511\\n87,511\\nSvevo\\nTetraploid wheat\\nMaccaferri et al. (2019)\\n115,437\\n115,437\\nTable 4 Performance comparison\\nof prediction models on wheat\\ndatasets\\nModel\\nHexaploid wheat\\nTetraploid wheat\\nACC\\nPRE\\nSN\\nF-\\nscore\\nACC\\nPRE\\nSN\\nF-\\nscore\\nQDA\\n92.79\\n0.88\\n1.00\\n0.93\\n94.27\\n0.90\\n1.00\\n0.95\\nNearestNeighbors\\n98.40\\n1.00\\n0.97\\n0.98\\n98.93\\n1.00\\n0.98\\n0.99\\nDecisionTree\\n96.19\\n0.99\\n0.94\\n0.96\\n97.03\\n0.99\\n0.95\\n0.97\\nRandomForest\\n98.65\\n1.00\\n0.98\\n0.99\\n99.25\\n1.00\\n0.99\\n0.99\\nNeuralNet\\n96.66\\n1.00\\n0.93\\n0.97\\n97.64\\n1.00\\n0.95\\n0.98\\nAdaBoost\\n97.84\\n1.00\\n0.96\\n0.98\\n98.75\\n1.00\\n0.98\\n0.99\\nNaiveBayes\\n93.00\\n0.88\\n1.00\\n0.93\\n94.27\\n0.90\\n1.00\\n0.95\\nLogisticRegression\\n96.58\\n0.94\\n0.99\\n0.97\\n97.77\\n0.96\\n1.00\\n0.98\\nLinearSVM\\n97.37\\n0.96\\n0.98\\n0.97\\n98.62\\n0.97\\n1.00\\n0.99\\nOther tools\\nCPC2\\n96.64\\n0.99\\n0.94\\n0.97\\n97.93\\n1.00\\n0.96\\n0.98\\nCPAT\\n98.06\\n0.98\\n0.98\\n0.98\\n99.03\\n0.98\\n1.00\\n0.99\\nCNIT\\n94.82\\n0.95\\n0.95\\n0.95\\n97.48\\n0.99\\n0.96\\n0.97\\nACC accuracy, PRE precision, SN sensitivity, SP specificity. Highest values of the metrics were shown in italics\\nFunct Integr Genomics\\nresemble coding sequences. Homology and alignment-based\\nmethods are highly dependent on the availability of prior data\\nand the evidence of sequence conservation between species.\\nHowever, this is insufficient when considering species-\\nspecific sequences and/or non-conserved sequences.\\nTherefore, it is crucial to find better methods of classification\\nto promote accurate identification of coding and noncoding\\nsequences.\\nAlthough there have been many proposed lncRNA coding\\nprediction tools (Han et al. 2016; Ventola et al. 2017), only\\nlimited sources are available for crop plants (Singh et al. 2017;\\nGuo et al. 2019; Negri et al. 2019). Additionally, most plant-\\nspecific tools that have been developed are difficult to imple-\\nment for further studies. The most trusted tools for the coding\\npotential predictions include CPAT (Wang et al. 2013), CPC2\\n(Kang et al. 2017), and CNIT (Guo et al. 2019), which have all\\nbeen improved and updated recently. Here, we investigated\\nseveral features to distinguish coding and noncoding se-\\nquences in crop plants, compared several algorithms for their\\nefficiencies with different sets of data, and provided perfor-\\nmance measures for these tools.\\nThe performances of machine learning models highly de-\\npend on the training data and the selected features. Several\\nfeatures proposed by different studies have been shown to\\nbe informative in the classification of coding and noncoding\\ntranscripts (Wang et al. 2013; Kang et al. 2017; Ito et al. 2018;\\nGuo et al. 2019). These features include k-mers, basic struc-\\ntural features like length and GC content, Fickett score,\\nhexamer score, ORF integrity, and isoelectric point.\\nAlthough each of these features was proposed as good\\nrepresentatives of the differences between coding and noncod-\\ning sequences, no single feature has been proposed as the most\\nsuperior. A combination of several features has typically been\\nused in previous studies (Simopoulos et al. 2018; Negri et al.\\n2019). After collecting the features suggested by the most\\ncommonly used prediction tools, we compiled a list of 93\\nfeatures, most of which were collinear. Our results showed\\nthat various feature selection algorithms, which proposed dif-\\nferent sets of features, did not necessarily result in better clas-\\nsifications (Table S1). By comparing all feature selection strat-\\negies, we were able to obtain the best representation of coding\\nand noncoding sequences. Overall, our results show that the\\nfinal set of features (sequence length, ORF length, GC%, and\\npI) are suitable for the most algorithms. This combination of\\nfeatures has not previously been used, although individually\\neach feature has been included in several other studies (Wang\\net al. 2013; Kang et al. 2017; Simopoulos et al. 2018).\\nIn this study, we proposed an accurate model, LncMachine\\nwith RandomForest, for lncRNA and mRNA identification in\\nwheat and other crop species. As training data, we used the\\ncomprehensive set of plant lncRNAs deposited in\\nCANTATAdb v2. Among many other lncRNA databases,\\nCANTATAdb was updated recently and receives regular support\\nand maintenance (Szcześniak et al. 2019). As for the feature set,\\nwe incorporated a final set of four features to achieve better\\nprediction accuracies. With comprehensive training data and a\\nsubstantial list of features, we compared nine different algorithms\\nfor their prediction performances using the same training data\\nand the same feature sets. Interestingly, training accuracies were\\nover 87% for all the algorithms with the top performing at 94%\\nFig. 3 The Receiver Operating Characteristic (ROC) curves of hexaploid and tetraploid wheat datasets using the LncMachine with the best three\\nalgorithms and other tools (CPAT, CPC2, and CNIT)\\nFunct Integr Genomics\\naccuracy (Table 1), indicating a good fit between the selected\\nfeatures and the training data.\\nComparison of these algorithms and the most trusted tools\\nlike CPAT, CPC2, and CNIT in various test sets showed that\\nno single prediction model outperformed all the other tools\\nand models in every setting. Instead, it was observed that each\\ntool performed differently for different datasets (Table S3).\\nDepending on the purpose of the study, we suggest using\\nLncMachine with different algorithms for different species:\\nRandom Forest, as default algorithm, suitable for both plants\\n(Table 4) and non-plant species (Table S3), and Logistic\\nRegression and Neural Networks for unbalanced datasets or\\nto introduce a bias for lncRNA predictions. Finally,\\nLncMachine is able to implement several algorithms, provid-\\ning the best adaptable model. As it is highly customizable, it\\ncan be applied across a wide range of studies. LncMachine\\nwill be a valuable contribution to the rapidly growing field of\\nbiological machine learning.\\nSupplementary Information The online version contains supplementary\\nmaterial available at https://doi.org/10.1007/s10142-021-00769-w.\\nAcknowledgements HB acknowledges Montana BioAg Inc. and this\\nwork is dedicated to Mr. Lyle Benjamin (past president of the MGGA),\\nwho recently left the farm industry but remains an avid supporter of\\nscience. His advocacy for innovation, and unwavering belief, has been\\ninvaluable in integrating agricultural research into Montana farms. SG\\nacknowledges project P18-RT-992 from Junta de Andalucía\\n(Andalusian Regional Government), Spain (co-funded by FEDER).\\nHBC was supported by TUBITAK for her PhD and the Oak Ridge\\nInstitute for Science and Education (ORISE) through an interagency\\nagreement between the US Department of Energy (DOE) and the US\\nDepartment of Agriculture (USDA) Agricultural Research Service\\n(ARS). This research was supported by the USDA-ARS Project\\nNumber 2030-21000-024-00-D (HB and TZS). USDA is an equal oppor-\\ntunity provider and employer.\\nData availability The datasets supporting the conclusions of this article\\nare included within the article as Supplementary Material. LncMachine\\ntogether with prebuilt prediction models and the training/test datasets are\\navailable through GitHub at https://github.com/hbusra/lncMachine.git.\\nCompliance with ethical standards\\nCompeting interests\\nThe authors declare no competing interests.'}\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for paper_title, pdf_file_path in zip(paper_titles, paper_pdf_file_paths):\n",
    "    print('-'*80)\n",
    "    print(f'processing: {paper_title}')\n",
    "    print('-'*80)\n",
    "    result = extract_sections_from_pdf(pdf_file_path=pdf_file_path)\n",
    "    print('-'*80)\n",
    "    print(result)\n",
    "    if cnt < 10:\n",
    "        break\n",
    "    else:\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "432594ae-dfa9-42cd-a599-4b86db767194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Introduction', 'Results', 'Discussion']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79dcf9e-221b-4919-8872-2de98a2cd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = dict()\n",
    "for s in result.keys():\n",
    "    text = result[s]\n",
    "    doc = nlp(text)\n",
    "                \n",
    "    # Detect entities\n",
    "    for ent in doc.ents:        \n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            break\n",
    "            if ent.text in search_results:\n",
    "                search_results[ent.text] += 1\n",
    "            else:\n",
    "                search_results[ent.text] = 1  # Store the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e093785c-ba29-4a64-ac95-df7286978b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf55410-af7b-4cf2-b260-94e2a5e80805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML_METHOD'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent.label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b4f9df7-b575-4b57-88da-f9c2a35e286b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaBoost'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "773f6aa6-ceea-4783-916b-f1d6c17ac81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoost"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5da89d20-787e-4fa3-a8b9-028510c69def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent.id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2606897-e9ff-46f8-b106-2a0ca63dd473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
