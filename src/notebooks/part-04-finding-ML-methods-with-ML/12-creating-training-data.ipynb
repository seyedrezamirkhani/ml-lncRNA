{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbeece59-564f-417b-beae-16307ba164a3",
   "metadata": {},
   "source": [
    "1. Label data using Named Entity Recognition\n",
    "2. Split data into train and test\n",
    "3. train model\n",
    "4. test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a945fa7-ee47-4ad7-9aaa-21a7c13ec3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from scholarly import scholarly\n",
    "\n",
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "\n",
    "import uuid\n",
    "\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dc9ad0-e2d9-4529-a0e5-2723f04b88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = '../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb4fc23-04fe-40d3-9637-c3782a5c4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095e3e86-7a0a-4d66-bb1a-3a67e000d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECT_ML_MODEL_FILES_FOLDER = '../../detect_ml_model_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c17b22-80d3-47da-af29-f1d2157a24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_excel(f'{ROOT_FOLDER}ML-Model-Categorization.ods', sheet_name='Sheet1', usecols=['MODEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0aab8e-1d81-46ef-a36b-be4294142760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elastic Net Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LLaMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Contrastive Language-Image Pretraining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>DALL-E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Stable Diffusion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      MODEL\n",
       "0                         Linear Regression\n",
       "1                     Polynomial Regression\n",
       "2                          Ridge Regression\n",
       "3                          Lasso Regression\n",
       "4                    Elastic Net Regression\n",
       "..                                      ...\n",
       "97                                   Claude\n",
       "98                                    LLaMA\n",
       "99   Contrastive Language-Image Pretraining\n",
       "100                                  DALL-E\n",
       "101                        Stable Diffusion\n",
       "\n",
       "[102 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7464cb50-e4ed-4d74-b25f-9e69dd975169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.entityruler.EntityRuler at 0x7173db597210>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp = spacy.blank(\"en\")\n",
    "# ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "#ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])  # Exclude the default NER component\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", last=True)\n",
    "\n",
    "# Load the EntityRuler patterns from a file\n",
    "ruler.from_disk(f\"{DATA_FOLDER}ml_entity_ruler_patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14753302-f5c6-4243-8331-611eab955003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine ML_METHOD\n",
      "Support Vector Machines ML_METHOD\n",
      "SVM ML_METHOD\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline\n",
    "text = \"Support Vector Machine, Support Vector Machines, SVM, and S.V.M. are popular machine learning methods.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print detected entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78859dec-b0c5-4896-9211-14346ed671bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = model_df['MODEL'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee84f69-a7de-403c-b401-2cfc77042a64",
   "metadata": {},
   "source": [
    "Find terms in file to use as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7001446-b89d-4431-b4fd-c1aa24326740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_file(pdf_file_path):\n",
    "    search_results = dict()\n",
    "    # Extract text from PDF\n",
    "    with open(pdf_file_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page_num, page in enumerate(pdf_reader.pages):\n",
    "            # Extract text from the page\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                # Use spaCy to process the text\n",
    "                doc = nlp(text)\n",
    "                \n",
    "                # Detect entities\n",
    "                for ent in doc.ents:\n",
    "                    if ent.label_ == \"ML_METHOD\":\n",
    "                        if ent.text in search_results:\n",
    "                            search_results[ent.text].append(page_num + 1)  # Store page number (1-indexed)\n",
    "                        else:\n",
    "                            search_results[ent.text] = [page_num + 1]  # Store page number (1-indexed)\n",
    "    \n",
    "    # Display search results\n",
    "    for term, pages in search_results.items():\n",
    "        if pages:\n",
    "            print(f\"'{term}' found on page(s): {set(pages)}\")\n",
    "        #else:\n",
    "        #    print(f\"'{term}' not found in the document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bd5f942-37b9-4786-8644-d44926ce1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = data_df['file_path'].dropna().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81596f97-d434-47a7-b4c8-55eca8cefdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../detect_ml_model_files/18d9a07e-aaa5-4cbe-a094-ccc035a96392.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_file_path = file_paths[0]\n",
    "\n",
    "print(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65a6ac06-5a89-45b4-96b1-0542b751f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pdf_file_path, \"rb\") as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    for page_num, page in enumerate(pdf_reader.pages):\n",
    "        # Extract text from the page\n",
    "        text = page.extract_text()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f688acc-3ed2-4fd7-8acf-cde835755a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64d48217-6075-4ae0-8c78-6d1b91a96c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "linear regression\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21167328-394c-4e76-a084-9e51cde8829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "Daniel Hsu (COMS 4771)\n",
      "Maximum likelihood estimation\n",
      "One of the simplest linear regression models is the following: (X1,Y1),..., (Xn,Yn),(X,Y)are iid random\n",
      "pairs taking values in Rd×R, and\n",
      "Y|X=x∼N(xTw,σ2),x∈Rd.\n",
      "\n",
      "Here, the vector w∈Rdand scalarσ2>0are the parameters of the model.\n",
      "(The marginal distribution of\n",
      "Xis unspeciﬁed.)\n",
      "\n",
      "Thelog-likelihood of(w,σ2)given (Xi,Yi)\n",
      "= (xi,yi)fori= 1,...,nis\n",
      "n/summationdisplay\n",
      "i=1/braceleftBigg\n",
      "ln1√\n",
      "2πσ2−(yi−xT\n",
      "iw)2\n",
      "2σ2/bracerightBigg\n",
      "+T,\n",
      "whereTis some quantity that does not depend on (w,σ2).\n",
      "Therefore, maximizing the log-likelihood over\n",
      "w∈Rd(for anyσ2>0) is the same as minimizing\n",
      "1\n",
      "nn/summationdisplay\n",
      "i=1(xT\n",
      "iw−yi)2.\n",
      "\n",
      "So, the maximum likelihood estimator (MLE) ofwin this model is\n",
      "ˆw∈arg min\n",
      "w∈Rd1\n",
      "nn/summationdisplay\n",
      "i=1(xT\n",
      "iw−yi)2.\n",
      "\n",
      "(It is not necessarily uniquely determined.)\n",
      "\n",
      "Empirical risk minimization\n",
      "LetPnbe the empirical distribution on(x1,y1),..., (xn,yn)∈Rd×R, i.e., the probability distribution over\n",
      "Rd×Rwith probability mass function pngiven by\n",
      "pn((x,y))\n",
      "=1\n",
      "nn/summationdisplay\n",
      "i=11{(x,y)=(xi,yi)},(x,y)∈Rd×R.\n",
      "The distribution assigns probability mass 1/nto each (xi,yi)fori= 1,...,n; no mass is assigned anywhere\n",
      "else.\n",
      "Now consider (˜X,˜Y)∼Pn.\n",
      "The expected squared loss of the linear function w∈Rdon(˜X,˜Y)is\n",
      "/hatwideR(w):=E[(˜XTw−˜Y)2] =1\n",
      "nn/summationdisplay\n",
      "i=1(xT\n",
      "iw−yi)2;\n",
      "we call this the empirical risk ofwon the data (x1,y1),..., (xn,yn).\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#nlp.add_pipe(\"sentencizer\", before=\"parser\")\n",
    "\n",
    "# Recreate the Doc object\n",
    "#doc = nlp(text)\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "343d8e8e-7e11-4c8a-822e-6699dfb52fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #f6c5be; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Linear regression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ML_METHOD</span>\n",
       "</mark>\n",
       "<br>Daniel Hsu (COMS 4771)<br>Maximum likelihood estimation<br>One of the simplest \n",
       "<mark class=\"entity\" style=\"background: #f6c5be; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    linear regression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ML_METHOD</span>\n",
       "</mark>\n",
       " models is the following: (X1,Y1),..., (Xn,Yn),(X,Y)are iid random<br>pairs taking values in Rd×R, and<br>Y|X=x∼N(xTw,σ2),x∈Rd.<br>Here, the vector w∈Rdand scalarσ2&gt;0are the parameters of the model. (The marginal distribution of<br>Xis unspeciﬁed.)<br>Thelog-likelihood of(w,σ2)given (Xi,Yi) = (xi,yi)fori= 1,...,nis<br>n/summationdisplay<br>i=1/braceleftBigg<br>ln1√<br>2πσ2−(yi−xT<br>iw)2<br>2σ2/bracerightBigg<br>+T,<br>whereTis some quantity that does not depend on (w,σ2). Therefore, maximizing the log-likelihood over<br>w∈Rd(for anyσ2&gt;0) is the same as minimizing<br>1<br>nn/summationdisplay<br>i=1(xT<br>iw−yi)2.<br>So, the maximum likelihood estimator (MLE) ofwin this model is<br>ˆw∈arg min<br>w∈Rd1<br>nn/summationdisplay<br>i=1(xT<br>iw−yi)2.<br>(It is not necessarily uniquely determined.)<br>Empirical risk minimization<br>LetPnbe the empirical distribution on(x1,y1),..., (xn,yn)∈Rd×R, i.e., the probability distribution over<br>Rd×Rwith probability mass function pngiven by<br>pn((x,y)) =1<br>nn/summationdisplay<br>i=11{(x,y)=(xi,yi)},(x,y)∈Rd×R.<br>The distribution assigns probability mass 1/nto each (xi,yi)fori= 1,...,n; no mass is assigned anywhere<br>else. Now consider (˜X,˜Y)∼Pn. The expected squared loss of the linear function w∈Rdon(˜X,˜Y)is<br>/hatwideR(w):=E[(˜XTw−˜Y)2] =1<br>nn/summationdisplay<br>i=1(xT<br>iw−yi)2;<br>we call this the empirical risk ofwon the data (x1,y1),..., (xn,yn).<br>1</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# Render the entities in a Jupyter Notebook or as HTML\n",
    "# displacy.render(doc, style=\"ent\", jupyter=True)  # Use jupyter=True if in a notebook\n",
    "\n",
    "options = {\"colors\": {\"ORG\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", \"ML_METHOD\": \"#f6c5be\"}}\n",
    "displacy.render(doc, style=\"ent\", options=options, jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27735c14-b2a0-4c2c-880f-d7a392348409",
   "metadata": {},
   "source": [
    "Lets only select sentences with a ML_METHOD entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d072f8a-d143-47dd-bf9f-0c78ef34a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentences:\n",
      "Linear regression\n",
      "Daniel Hsu (COMS 4771)\n",
      "Maximum likelihood estimation\n",
      "One of the simplest linear regression models is the following: (X1,Y1),..., (Xn,Yn),(X,Y)are iid random\n",
      "pairs taking values in Rd×R, and\n",
      "Y|X=x∼N(xTw,σ2),x∈Rd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract sentences with ML_METHOD entities\n",
    "filtered_sentences = [\n",
    "    sentence.text\n",
    "    for sentence in doc.sents\n",
    "    if any(ent.label_ == \"ML_METHOD\" for ent in sentence.ents)\n",
    "]\n",
    "\n",
    "# Create a new text containing only those sentences\n",
    "filtered_text = \" \".join(filtered_sentences)\n",
    "\n",
    "# Create a new Doc object with the filtered text\n",
    "filtered_doc = nlp(filtered_text)\n",
    "\n",
    "# Print the filtered sentences\n",
    "print(\"Filtered Sentences:\")\n",
    "for sentence in filtered_doc.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b10c9acd-b9c1-495b-b51d-1b3a3505145b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Linear regression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ML_METHOD</span>\n",
       "</mark>\n",
       "<br>Daniel Hsu (COMS 4771)<br>Maximum likelihood estimation<br>One of the simplest \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    linear regression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ML_METHOD</span>\n",
       "</mark>\n",
       " models is the following: (X1,Y1),..., (Xn,Yn),(X,Y)are iid random<br>pairs taking values in Rd×R, and<br>Y|X=x∼N(xTw,σ2),x∈Rd.<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displacy.render(filtered_doc, style=\"ent\", jupyter=True)  # Use jupyter=True if in a notebook\n",
    "\n",
    "options = {\"colors\": {\"ML_METHOD\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}}\n",
    "displacy.render(filtered_doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b649f4-54a1-4925-afad-69bb57e00b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
