{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbeece59-564f-417b-beae-16307ba164a3",
   "metadata": {},
   "source": [
    "1. Label data using Named Entity Recognition\n",
    "2. Split data into train and test\n",
    "3. train model\n",
    "4. test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a945fa7-ee47-4ad7-9aaa-21a7c13ec3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from scholarly import scholarly\n",
    "\n",
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "\n",
    "import uuid\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dc9ad0-e2d9-4529-a0e5-2723f04b88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = '../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb4fc23-04fe-40d3-9637-c3782a5c4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095e3e86-7a0a-4d66-bb1a-3a67e000d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECT_ML_MODEL_FILES_FOLDER = '../../../detect_ml_model_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c17b22-80d3-47da-af29-f1d2157a24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_parquet(f'{DATA_FOLDER}detect_ml_models.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3a3fb8-561f-4559-b62e-73d16ff45820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records where the file_name is Null\n",
    "data_df = data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0aab8e-1d81-46ef-a36b-be4294142760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>author_id</th>\n",
       "      <th>query</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression</td>\n",
       "      <td>Linear regression plays a fundamental role in ...</td>\n",
       "      <td>2012</td>\n",
       "      <td>https://www.cs.columbia.edu/~djhsu/coms4771-f2...</td>\n",
       "      <td>[wcgZZP8AAAAJ, , El-UNYoAAAAJ]</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>7cedd2b0-ac03-49fb-9ef1-398b1a5d7fe1.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/7cedd2b0-ac03-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Introduction to linear regression analysis</td>\n",
       "      <td>Equation (1.2) is called a linear regression m...</td>\n",
       "      <td>2021</td>\n",
       "      <td>http://sutlib2.sut.ac.th/sut_contents/H133678.pdf</td>\n",
       "      <td>[5PboKNAAAAAJ, , y2eb6cQAAAAJ]</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>91374318-7135-4f51-a3bc-720ececd88de.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/91374318-7135-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear regression</td>\n",
       "      <td>linear regression, a very simple approach for ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://datamineaz.org/readings/ISL_chp3.pdf</td>\n",
       "      <td>[KUIjZqgAAAAJ, bHZf-c8AAAAJ, tQVe-fAAAAAJ, ZpG...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>6d3627b9-6b0b-423c-8898-3185837a7617.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/6d3627b9-6b0b-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Applied linear regression</td>\n",
       "      <td>Applied linear regression Applied linear regre...</td>\n",
       "      <td>2005</td>\n",
       "      <td>https://www.stat.cmu.edu/~brian/valerie/617-20...</td>\n",
       "      <td>[wlu6jZQAAAAJ]</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>c7fed73c-8e13-4770-a589-67708aab0b7e.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/c7fed73c-8e13-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A review on linear regression comprehensive in...</td>\n",
       "      <td>We discuss linear regression and polynomial re...</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://jastt.org/index.php/jasttpath/article/...</td>\n",
       "      <td>[G9U01kwAAAAJ, aBdgHxkAAAAJ]</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>f8d408d7-9c86-4d72-b6af-6538ed46970f.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/f8d408d7-9c86-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>BERT: a review of applications in natural lang...</td>\n",
       "      <td>relative to the original BERT model, which is ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://arxiv.org/pdf/2103.11943</td>\n",
       "      <td>[]</td>\n",
       "      <td>BERT</td>\n",
       "      <td>91ebf298-65bd-4429-8c60-b17cb80306fe.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/91ebf298-65bd-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>What does BERT learn about the structure of la...</td>\n",
       "      <td>language structure learned by BERT. We first s...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://inria.hal.science/hal-02131630/document</td>\n",
       "      <td>[X7SMP1EAAAAJ, HXUT9ZkAAAAJ, P7EtARsAAAAJ]</td>\n",
       "      <td>BERT</td>\n",
       "      <td>65f04db1-ad62-4f48-9e80-3ae5a11bf147.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/65f04db1-ad62-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>Visualizing and understanding the effectivenes...</td>\n",
       "      <td>trajectories of fine-tuning BERT on specific d...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://arxiv.org/pdf/1908.05620</td>\n",
       "      <td>[cqOLO7IAAAAJ, wEfQgPgAAAAJ, G-V1VpwAAAAJ, ]</td>\n",
       "      <td>BERT</td>\n",
       "      <td>03d43387-8413-413c-8ce8-92b3512cedfb.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/03d43387-8413-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>A comprehensive survey on pretrained foundatio...</td>\n",
       "      <td>Pretrained Foundation Models (PFMs) are regard...</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://arxiv.org/pdf/2302.09419</td>\n",
       "      <td>[HWx73DcAAAAJ, AHg-JGIAAAAJ, nPvWFpkAAAAJ, fh1...</td>\n",
       "      <td>BERT</td>\n",
       "      <td>a60911d8-b83b-4c2a-8555-2ac3b09b5025.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/a60911d8-b83b-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>Bertje: A dutch bert model</td>\n",
       "      <td>a monolingual Dutch BERT model called BERTje. ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://arxiv.org/pdf/1912.09582</td>\n",
       "      <td>[gZkWURYAAAAJ, Y745fFYAAAAJ, biQvUhcAAAAJ]</td>\n",
       "      <td>BERT</td>\n",
       "      <td>98aa5e73-a662-448f-bca7-ff87bc1cc5bb.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/98aa5e73-a662-4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                                     Linear regression   \n",
       "1            Introduction to linear regression analysis   \n",
       "2                                     Linear regression   \n",
       "4                             Applied linear regression   \n",
       "8     A review on linear regression comprehensive in...   \n",
       "...                                                 ...   \n",
       "1227  BERT: a review of applications in natural lang...   \n",
       "1228  What does BERT learn about the structure of la...   \n",
       "1229  Visualizing and understanding the effectivenes...   \n",
       "1230  A comprehensive survey on pretrained foundatio...   \n",
       "1231                         Bertje: A dutch bert model   \n",
       "\n",
       "                                               abstract  year  \\\n",
       "0     Linear regression plays a fundamental role in ...  2012   \n",
       "1     Equation (1.2) is called a linear regression m...  2021   \n",
       "2     linear regression, a very simple approach for ...  2023   \n",
       "4     Applied linear regression Applied linear regre...  2005   \n",
       "8     We discuss linear regression and polynomial re...  2020   \n",
       "...                                                 ...   ...   \n",
       "1227  relative to the original BERT model, which is ...  2021   \n",
       "1228  language structure learned by BERT. We first s...  2019   \n",
       "1229  trajectories of fine-tuning BERT on specific d...  2019   \n",
       "1230  Pretrained Foundation Models (PFMs) are regard...  2024   \n",
       "1231  a monolingual Dutch BERT model called BERTje. ...  2019   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.cs.columbia.edu/~djhsu/coms4771-f2...   \n",
       "1     http://sutlib2.sut.ac.th/sut_contents/H133678.pdf   \n",
       "2          https://datamineaz.org/readings/ISL_chp3.pdf   \n",
       "4     https://www.stat.cmu.edu/~brian/valerie/617-20...   \n",
       "8     https://jastt.org/index.php/jasttpath/article/...   \n",
       "...                                                 ...   \n",
       "1227                   https://arxiv.org/pdf/2103.11943   \n",
       "1228    https://inria.hal.science/hal-02131630/document   \n",
       "1229                   https://arxiv.org/pdf/1908.05620   \n",
       "1230                   https://arxiv.org/pdf/2302.09419   \n",
       "1231                   https://arxiv.org/pdf/1912.09582   \n",
       "\n",
       "                                              author_id              query  \\\n",
       "0                        [wcgZZP8AAAAJ, , El-UNYoAAAAJ]  Linear Regression   \n",
       "1                        [5PboKNAAAAAJ, , y2eb6cQAAAAJ]  Linear Regression   \n",
       "2     [KUIjZqgAAAAJ, bHZf-c8AAAAJ, tQVe-fAAAAAJ, ZpG...  Linear Regression   \n",
       "4                                        [wlu6jZQAAAAJ]  Linear Regression   \n",
       "8                          [G9U01kwAAAAJ, aBdgHxkAAAAJ]  Linear Regression   \n",
       "...                                                 ...                ...   \n",
       "1227                                                 []               BERT   \n",
       "1228         [X7SMP1EAAAAJ, HXUT9ZkAAAAJ, P7EtARsAAAAJ]               BERT   \n",
       "1229       [cqOLO7IAAAAJ, wEfQgPgAAAAJ, G-V1VpwAAAAJ, ]               BERT   \n",
       "1230  [HWx73DcAAAAJ, AHg-JGIAAAAJ, nPvWFpkAAAAJ, fh1...               BERT   \n",
       "1231         [gZkWURYAAAAJ, Y745fFYAAAAJ, biQvUhcAAAAJ]               BERT   \n",
       "\n",
       "                                     file_name  \\\n",
       "0     7cedd2b0-ac03-49fb-9ef1-398b1a5d7fe1.pdf   \n",
       "1     91374318-7135-4f51-a3bc-720ececd88de.pdf   \n",
       "2     6d3627b9-6b0b-423c-8898-3185837a7617.pdf   \n",
       "4     c7fed73c-8e13-4770-a589-67708aab0b7e.pdf   \n",
       "8     f8d408d7-9c86-4d72-b6af-6538ed46970f.pdf   \n",
       "...                                        ...   \n",
       "1227  91ebf298-65bd-4429-8c60-b17cb80306fe.pdf   \n",
       "1228  65f04db1-ad62-4f48-9e80-3ae5a11bf147.pdf   \n",
       "1229  03d43387-8413-413c-8ce8-92b3512cedfb.pdf   \n",
       "1230  a60911d8-b83b-4c2a-8555-2ac3b09b5025.pdf   \n",
       "1231  98aa5e73-a662-448f-bca7-ff87bc1cc5bb.pdf   \n",
       "\n",
       "                                              file_path  \n",
       "0     ../../../detect_ml_model_files/7cedd2b0-ac03-4...  \n",
       "1     ../../../detect_ml_model_files/91374318-7135-4...  \n",
       "2     ../../../detect_ml_model_files/6d3627b9-6b0b-4...  \n",
       "4     ../../../detect_ml_model_files/c7fed73c-8e13-4...  \n",
       "8     ../../../detect_ml_model_files/f8d408d7-9c86-4...  \n",
       "...                                                 ...  \n",
       "1227  ../../../detect_ml_model_files/91ebf298-65bd-4...  \n",
       "1228  ../../../detect_ml_model_files/65f04db1-ad62-4...  \n",
       "1229  ../../../detect_ml_model_files/03d43387-8413-4...  \n",
       "1230  ../../../detect_ml_model_files/a60911d8-b83b-4...  \n",
       "1231  ../../../detect_ml_model_files/98aa5e73-a662-4...  \n",
       "\n",
       "[495 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afef6c3-ae42-430e-8e7a-8054c645799c",
   "metadata": {},
   "source": [
    "The query column represents the machine learning model name that was used to search Google Scholar.\n",
    "\n",
    "There should be five papers per model.\n",
    "\n",
    "Add a new column to represent an identifier/order for the paper within each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9bde7e9-ab1a-4c51-8cfc-7cbddcd0f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df['counter'] = data_df.groupby('query').cumcount() + 1\n",
    "data_df.loc[:, 'counter'] = data_df.groupby('query').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a64178c-8002-4a32-aee8-dc1d6e17cbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>author_id</th>\n",
       "      <th>query</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression</td>\n",
       "      <td>Linear regression plays a fundamental role in ...</td>\n",
       "      <td>2012</td>\n",
       "      <td>https://www.cs.columbia.edu/~djhsu/coms4771-f2...</td>\n",
       "      <td>[wcgZZP8AAAAJ, , El-UNYoAAAAJ]</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>7cedd2b0-ac03-49fb-9ef1-398b1a5d7fe1.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/7cedd2b0-ac03-4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Introduction to linear regression analysis</td>\n",
       "      <td>Equation (1.2) is called a linear regression m...</td>\n",
       "      <td>2021</td>\n",
       "      <td>http://sutlib2.sut.ac.th/sut_contents/H133678.pdf</td>\n",
       "      <td>[5PboKNAAAAAJ, , y2eb6cQAAAAJ]</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>91374318-7135-4f51-a3bc-720ececd88de.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/91374318-7135-4...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear regression</td>\n",
       "      <td>linear regression, a very simple approach for ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://datamineaz.org/readings/ISL_chp3.pdf</td>\n",
       "      <td>[KUIjZqgAAAAJ, bHZf-c8AAAAJ, tQVe-fAAAAAJ, ZpG...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>6d3627b9-6b0b-423c-8898-3185837a7617.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/6d3627b9-6b0b-4...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Applied linear regression</td>\n",
       "      <td>Applied linear regression Applied linear regre...</td>\n",
       "      <td>2005</td>\n",
       "      <td>https://www.stat.cmu.edu/~brian/valerie/617-20...</td>\n",
       "      <td>[wlu6jZQAAAAJ]</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>c7fed73c-8e13-4770-a589-67708aab0b7e.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/c7fed73c-8e13-4...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A review on linear regression comprehensive in...</td>\n",
       "      <td>We discuss linear regression and polynomial re...</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://jastt.org/index.php/jasttpath/article/...</td>\n",
       "      <td>[G9U01kwAAAAJ, aBdgHxkAAAAJ]</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>f8d408d7-9c86-4d72-b6af-6538ed46970f.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/f8d408d7-9c86-4...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>BERT: a review of applications in natural lang...</td>\n",
       "      <td>relative to the original BERT model, which is ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://arxiv.org/pdf/2103.11943</td>\n",
       "      <td>[]</td>\n",
       "      <td>BERT</td>\n",
       "      <td>91ebf298-65bd-4429-8c60-b17cb80306fe.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/91ebf298-65bd-4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>What does BERT learn about the structure of la...</td>\n",
       "      <td>language structure learned by BERT. We first s...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://inria.hal.science/hal-02131630/document</td>\n",
       "      <td>[X7SMP1EAAAAJ, HXUT9ZkAAAAJ, P7EtARsAAAAJ]</td>\n",
       "      <td>BERT</td>\n",
       "      <td>65f04db1-ad62-4f48-9e80-3ae5a11bf147.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/65f04db1-ad62-4...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>Visualizing and understanding the effectivenes...</td>\n",
       "      <td>trajectories of fine-tuning BERT on specific d...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://arxiv.org/pdf/1908.05620</td>\n",
       "      <td>[cqOLO7IAAAAJ, wEfQgPgAAAAJ, G-V1VpwAAAAJ, ]</td>\n",
       "      <td>BERT</td>\n",
       "      <td>03d43387-8413-413c-8ce8-92b3512cedfb.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/03d43387-8413-4...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>A comprehensive survey on pretrained foundatio...</td>\n",
       "      <td>Pretrained Foundation Models (PFMs) are regard...</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://arxiv.org/pdf/2302.09419</td>\n",
       "      <td>[HWx73DcAAAAJ, AHg-JGIAAAAJ, nPvWFpkAAAAJ, fh1...</td>\n",
       "      <td>BERT</td>\n",
       "      <td>a60911d8-b83b-4c2a-8555-2ac3b09b5025.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/a60911d8-b83b-4...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>Bertje: A dutch bert model</td>\n",
       "      <td>a monolingual Dutch BERT model called BERTje. ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://arxiv.org/pdf/1912.09582</td>\n",
       "      <td>[gZkWURYAAAAJ, Y745fFYAAAAJ, biQvUhcAAAAJ]</td>\n",
       "      <td>BERT</td>\n",
       "      <td>98aa5e73-a662-448f-bca7-ff87bc1cc5bb.pdf</td>\n",
       "      <td>../../../detect_ml_model_files/98aa5e73-a662-4...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                                     Linear regression   \n",
       "1            Introduction to linear regression analysis   \n",
       "2                                     Linear regression   \n",
       "4                             Applied linear regression   \n",
       "8     A review on linear regression comprehensive in...   \n",
       "...                                                 ...   \n",
       "1227  BERT: a review of applications in natural lang...   \n",
       "1228  What does BERT learn about the structure of la...   \n",
       "1229  Visualizing and understanding the effectivenes...   \n",
       "1230  A comprehensive survey on pretrained foundatio...   \n",
       "1231                         Bertje: A dutch bert model   \n",
       "\n",
       "                                               abstract  year  \\\n",
       "0     Linear regression plays a fundamental role in ...  2012   \n",
       "1     Equation (1.2) is called a linear regression m...  2021   \n",
       "2     linear regression, a very simple approach for ...  2023   \n",
       "4     Applied linear regression Applied linear regre...  2005   \n",
       "8     We discuss linear regression and polynomial re...  2020   \n",
       "...                                                 ...   ...   \n",
       "1227  relative to the original BERT model, which is ...  2021   \n",
       "1228  language structure learned by BERT. We first s...  2019   \n",
       "1229  trajectories of fine-tuning BERT on specific d...  2019   \n",
       "1230  Pretrained Foundation Models (PFMs) are regard...  2024   \n",
       "1231  a monolingual Dutch BERT model called BERTje. ...  2019   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.cs.columbia.edu/~djhsu/coms4771-f2...   \n",
       "1     http://sutlib2.sut.ac.th/sut_contents/H133678.pdf   \n",
       "2          https://datamineaz.org/readings/ISL_chp3.pdf   \n",
       "4     https://www.stat.cmu.edu/~brian/valerie/617-20...   \n",
       "8     https://jastt.org/index.php/jasttpath/article/...   \n",
       "...                                                 ...   \n",
       "1227                   https://arxiv.org/pdf/2103.11943   \n",
       "1228    https://inria.hal.science/hal-02131630/document   \n",
       "1229                   https://arxiv.org/pdf/1908.05620   \n",
       "1230                   https://arxiv.org/pdf/2302.09419   \n",
       "1231                   https://arxiv.org/pdf/1912.09582   \n",
       "\n",
       "                                              author_id              query  \\\n",
       "0                        [wcgZZP8AAAAJ, , El-UNYoAAAAJ]  Linear Regression   \n",
       "1                        [5PboKNAAAAAJ, , y2eb6cQAAAAJ]  Linear Regression   \n",
       "2     [KUIjZqgAAAAJ, bHZf-c8AAAAJ, tQVe-fAAAAAJ, ZpG...  Linear Regression   \n",
       "4                                        [wlu6jZQAAAAJ]  Linear Regression   \n",
       "8                          [G9U01kwAAAAJ, aBdgHxkAAAAJ]  Linear Regression   \n",
       "...                                                 ...                ...   \n",
       "1227                                                 []               BERT   \n",
       "1228         [X7SMP1EAAAAJ, HXUT9ZkAAAAJ, P7EtARsAAAAJ]               BERT   \n",
       "1229       [cqOLO7IAAAAJ, wEfQgPgAAAAJ, G-V1VpwAAAAJ, ]               BERT   \n",
       "1230  [HWx73DcAAAAJ, AHg-JGIAAAAJ, nPvWFpkAAAAJ, fh1...               BERT   \n",
       "1231         [gZkWURYAAAAJ, Y745fFYAAAAJ, biQvUhcAAAAJ]               BERT   \n",
       "\n",
       "                                     file_name  \\\n",
       "0     7cedd2b0-ac03-49fb-9ef1-398b1a5d7fe1.pdf   \n",
       "1     91374318-7135-4f51-a3bc-720ececd88de.pdf   \n",
       "2     6d3627b9-6b0b-423c-8898-3185837a7617.pdf   \n",
       "4     c7fed73c-8e13-4770-a589-67708aab0b7e.pdf   \n",
       "8     f8d408d7-9c86-4d72-b6af-6538ed46970f.pdf   \n",
       "...                                        ...   \n",
       "1227  91ebf298-65bd-4429-8c60-b17cb80306fe.pdf   \n",
       "1228  65f04db1-ad62-4f48-9e80-3ae5a11bf147.pdf   \n",
       "1229  03d43387-8413-413c-8ce8-92b3512cedfb.pdf   \n",
       "1230  a60911d8-b83b-4c2a-8555-2ac3b09b5025.pdf   \n",
       "1231  98aa5e73-a662-448f-bca7-ff87bc1cc5bb.pdf   \n",
       "\n",
       "                                              file_path  counter  \n",
       "0     ../../../detect_ml_model_files/7cedd2b0-ac03-4...        1  \n",
       "1     ../../../detect_ml_model_files/91374318-7135-4...        2  \n",
       "2     ../../../detect_ml_model_files/6d3627b9-6b0b-4...        3  \n",
       "4     ../../../detect_ml_model_files/c7fed73c-8e13-4...        4  \n",
       "8     ../../../detect_ml_model_files/f8d408d7-9c86-4...        5  \n",
       "...                                                 ...      ...  \n",
       "1227  ../../../detect_ml_model_files/91ebf298-65bd-4...        1  \n",
       "1228  ../../../detect_ml_model_files/65f04db1-ad62-4...        2  \n",
       "1229  ../../../detect_ml_model_files/03d43387-8413-4...        3  \n",
       "1230  ../../../detect_ml_model_files/a60911d8-b83b-4...        4  \n",
       "1231  ../../../detect_ml_model_files/98aa5e73-a662-4...        5  \n",
       "\n",
       "[495 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7464cb50-e4ed-4d74-b25f-9e69dd975169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.entityruler.EntityRuler at 0x76c2a47b5090>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp = spacy.blank(\"en\")\n",
    "# ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "#ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])  # Exclude the default NER component\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", last=True)\n",
    "\n",
    "# Load the EntityRuler patterns from a file\n",
    "ruler.from_disk(f\"{DATA_FOLDER}ml_entity_ruler_patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffd747-68d1-48fc-9cc6-8525b7f4fcc0",
   "metadata": {},
   "source": [
    "Lets take the first four files for a model for training and the last one for test. This will give us a 80/20 split of files at least.\n",
    "\n",
    "The query results from Google Scholar are in descending order of popularity. This should mean that the files are not necessarily in order of published date, which is good.\n",
    "\n",
    "Further analysis is required to look at the terms in each file and create a more balanced training/test split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "608f3a4d-d8f8-4797-bc5c-a949a03f1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = data_df.query('counter < 5')['file_path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32743f69-da5f-47cd-9c32-5c4dcfe9e87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a50365-d04f-406c-8649-62e88b76f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = data_df.query('counter == 5')['file_path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d27744a-8c78-4f7e-84e8-2e0f0589aad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b755414-6152-4bcf-b03e-8d545a30c450",
   "metadata": {},
   "source": [
    "There should be 4 times more training_files than test_files, lets test that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44407da9-e794-49d5-ac21-06f440e24b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_files) * 4 == len(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c1bebb-84f3-43db-b0a7-07d174412500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupby(['query']).count().reset_index().query('counter != 5')['query'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafb97d-f5f6-45d7-b1fb-31a6f89422d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14753302-f5c6-4243-8331-611eab955003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine ML_METHOD\n",
      "Support Vector Machines ML_METHOD\n",
      "SVM ML_METHOD\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline\n",
    "text = \"Support Vector Machine, Support Vector Machines, SVM, and S.V.M. are popular machine learning methods.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print detected entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fffa85-3f6c-4568-add9-c2a0bf6a2e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee84f69-a7de-403c-b401-2cfc77042a64",
   "metadata": {},
   "source": [
    "Find terms in file to use as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abd622e5-573a-412c-bdac-eeeed46a5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labelled_docs(files):\n",
    "    docs = list()\n",
    "    for pdf_file_path in files:\n",
    "        with open(pdf_file_path, \"rb\") as pdf_file:\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            for page_num, page in enumerate(pdf_reader.pages):\n",
    "                # Extract text from the page\n",
    "                text = page.extract_text()\n",
    "                doc = nlp(text)\n",
    "\n",
    "                # Extract sentences with ML_METHOD entities\n",
    "                filtered_sentences = [\n",
    "                    sentence.text\n",
    "                    for sentence in doc.sents\n",
    "                    if any(ent.label_ == \"ML_METHOD\" for ent in sentence.ents)\n",
    "                ]\n",
    "\n",
    "                if len(filtered_sentences) > 0:\n",
    "                    # Create a new text containing only those sentences\n",
    "                    filtered_text = \" \".join(filtered_sentences)\n",
    "                    \n",
    "                    # Create a new Doc object with the filtered text\n",
    "                    filtered_doc = nlp(filtered_text)\n",
    "                    docs.append(filtered_doc)\n",
    "                    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c29c36a-9d9d-49cd-a70f-d992bbc5024b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_docs \u001b[38;5;241m=\u001b[39m create_labelled_docs(files\u001b[38;5;241m=\u001b[39mtraining_files)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(training_docs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere are no labels created for the requested files!!!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m, in \u001b[0;36mcreate_labelled_docs\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_num, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf_reader\u001b[38;5;241m.\u001b[39mpages):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Extract text from the page\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     text \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_text()\n\u001b[0;32m----> 9\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(text)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Extract sentences with ML_METHOD entities\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     filtered_sentences \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m         sentence\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ent\u001b[38;5;241m.\u001b[39mlabel_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mML_METHOD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39ments)\n\u001b[1;32m     16\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/spacy/language.py:1052\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1052\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(docs)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/layers/with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/layers/with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[1;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[1;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m layer(Xr\u001b[38;5;241m.\u001b[39mdataXd, is_train)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-lncRNA/lib/python3.12/site-packages/thinc/layers/maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     50\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape2f(W, nO \u001b[38;5;241m*\u001b[39m nP, nI)\n\u001b[0;32m---> 52\u001b[0m Y \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mgemm(X, W, trans2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape1f(b, nO \u001b[38;5;241m*\u001b[39m nP)\n\u001b[1;32m     54\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape3f(Y, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nO, nP)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_docs = create_labelled_docs(files=training_files)\n",
    "if len(training_docs) < 1:\n",
    "    print('There are no labels created for the requested files!!!')\n",
    "else:\n",
    "    # save it in a format spacy can use\n",
    "    training_doc_bin = DocBin(docs=training_docs)\n",
    "    training_doc_bin.to_disk(\"./train.spacy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089df7d2-052d-4319-b64f-0dbc5ce2ed46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e6ded-7f51-4fad-a16d-819002025940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d63731-9942-44d5-8134-69c9d113085f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7001446-b89d-4431-b4fd-c1aa24326740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_file(pdf_file_path):\n",
    "    search_results = dict()\n",
    "    # Extract text from PDF\n",
    "    with open(pdf_file_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page_num, page in enumerate(pdf_reader.pages):\n",
    "            # Extract text from the page\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                # Use spaCy to process the text\n",
    "                doc = nlp(text)\n",
    "                \n",
    "                # Detect entities\n",
    "                for ent in doc.ents:\n",
    "                    if ent.label_ == \"ML_METHOD\":\n",
    "                        if ent.text in search_results:\n",
    "                            search_results[ent.text].append(page_num + 1)  # Store page number (1-indexed)\n",
    "                        else:\n",
    "                            search_results[ent.text] = [page_num + 1]  # Store page number (1-indexed)\n",
    "    \n",
    "    # Display search results\n",
    "    for term, pages in search_results.items():\n",
    "        if pages:\n",
    "            print(f\"'{term}' found on page(s): {set(pages)}\")\n",
    "        #else:\n",
    "        #    print(f\"'{term}' not found in the document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bd5f942-37b9-4786-8644-d44926ce1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81596f97-d434-47a7-b4c8-55eca8cefdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../detect_ml_model_files/18d9a07e-aaa5-4cbe-a094-ccc035a96392.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_file_path = file_paths[0]\n",
    "\n",
    "print(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65a6ac06-5a89-45b4-96b1-0542b751f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pdf_file_path, \"rb\") as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    for page_num, page in enumerate(pdf_reader.pages):\n",
    "        # Extract text from the page\n",
    "        text = page.extract_text()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f688acc-3ed2-4fd7-8acf-cde835755a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64d48217-6075-4ae0-8c78-6d1b91a96c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "linear regression\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21167328-394c-4e76-a084-9e51cde8829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "Daniel Hsu (COMS 4771)\n",
      "Maximum likelihood estimation\n",
      "One of the simplest linear regression models is the following: (X1,Y1),..., (Xn,Yn),(X,Y)are iid random\n",
      "pairs taking values in Rd×R, and\n",
      "Y|X=x∼N(xTw,σ2),x∈Rd.\n",
      "\n",
      "Here, the vector w∈Rdand scalarσ2>0are the parameters of the model.\n",
      "(The marginal distribution of\n",
      "Xis unspeciﬁed.)\n",
      "\n",
      "Thelog-likelihood of(w,σ2)given (Xi,Yi)\n",
      "= (xi,yi)fori= 1,...,nis\n",
      "n/summationdisplay\n",
      "i=1/braceleftBigg\n",
      "ln1√\n",
      "2πσ2−(yi−xT\n",
      "iw)2\n",
      "2σ2/bracerightBigg\n",
      "+T,\n",
      "whereTis some quantity that does not depend on (w,σ2).\n",
      "Therefore, maximizing the log-likelihood over\n",
      "w∈Rd(for anyσ2>0) is the same as minimizing\n",
      "1\n",
      "nn/summationdisplay\n",
      "i=1(xT\n",
      "iw−yi)2.\n",
      "\n",
      "So, the maximum likelihood estimator (MLE) ofwin this model is\n",
      "ˆw∈arg min\n",
      "w∈Rd1\n",
      "nn/summationdisplay\n",
      "i=1(xT\n",
      "iw−yi)2.\n",
      "\n",
      "(It is not necessarily uniquely determined.)\n",
      "\n",
      "Empirical risk minimization\n",
      "LetPnbe the empirical distribution on(x1,y1),..., (xn,yn)∈Rd×R, i.e., the probability distribution over\n",
      "Rd×Rwith probability mass function pngiven by\n",
      "pn((x,y))\n",
      "=1\n",
      "nn/summationdisplay\n",
      "i=11{(x,y)=(xi,yi)},(x,y)∈Rd×R.\n",
      "The distribution assigns probability mass 1/nto each (xi,yi)fori= 1,...,n; no mass is assigned anywhere\n",
      "else.\n",
      "Now consider (˜X,˜Y)∼Pn.\n",
      "The expected squared loss of the linear function w∈Rdon(˜X,˜Y)is\n",
      "/hatwideR(w):=E[(˜XTw−˜Y)2] =1\n",
      "nn/summationdisplay\n",
      "i=1(xT\n",
      "iw−yi)2;\n",
      "we call this the empirical risk ofwon the data (x1,y1),..., (xn,yn).\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#nlp.add_pipe(\"sentencizer\", before=\"parser\")\n",
    "\n",
    "# Recreate the Doc object\n",
    "#doc = nlp(text)\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "343d8e8e-7e11-4c8a-822e-6699dfb52fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #f6c5be; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Linear regression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ML_METHOD</span>\n",
       "</mark>\n",
       "<br>Daniel Hsu (COMS 4771)<br>Maximum likelihood estimation<br>One of the simplest \n",
       "<mark class=\"entity\" style=\"background: #f6c5be; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    linear regression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ML_METHOD</span>\n",
       "</mark>\n",
       " models is the following: (X1,Y1),..., (Xn,Yn),(X,Y)are iid random<br>pairs taking values in Rd×R, and<br>Y|X=x∼N(xTw,σ2),x∈Rd.<br>Here, the vector w∈Rdand scalarσ2&gt;0are the parameters of the model. (The marginal distribution of<br>Xis unspeciﬁed.)<br>Thelog-likelihood of(w,σ2)given (Xi,Yi) = (xi,yi)fori= 1,...,nis<br>n/summationdisplay<br>i=1/braceleftBigg<br>ln1√<br>2πσ2−(yi−xT<br>iw)2<br>2σ2/bracerightBigg<br>+T,<br>whereTis some quantity that does not depend on (w,σ2). Therefore, maximizing the log-likelihood over<br>w∈Rd(for anyσ2&gt;0) is the same as minimizing<br>1<br>nn/summationdisplay<br>i=1(xT<br>iw−yi)2.<br>So, the maximum likelihood estimator (MLE) ofwin this model is<br>ˆw∈arg min<br>w∈Rd1<br>nn/summationdisplay<br>i=1(xT<br>iw−yi)2.<br>(It is not necessarily uniquely determined.)<br>Empirical risk minimization<br>LetPnbe the empirical distribution on(x1,y1),..., (xn,yn)∈Rd×R, i.e., the probability distribution over<br>Rd×Rwith probability mass function pngiven by<br>pn((x,y)) =1<br>nn/summationdisplay<br>i=11{(x,y)=(xi,yi)},(x,y)∈Rd×R.<br>The distribution assigns probability mass 1/nto each (xi,yi)fori= 1,...,n; no mass is assigned anywhere<br>else. Now consider (˜X,˜Y)∼Pn. The expected squared loss of the linear function w∈Rdon(˜X,˜Y)is<br>/hatwideR(w):=E[(˜XTw−˜Y)2] =1<br>nn/summationdisplay<br>i=1(xT<br>iw−yi)2;<br>we call this the empirical risk ofwon the data (x1,y1),..., (xn,yn).<br>1</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# Render the entities in a Jupyter Notebook or as HTML\n",
    "# displacy.render(doc, style=\"ent\", jupyter=True)  # Use jupyter=True if in a notebook\n",
    "\n",
    "options = {\"colors\": {\"ORG\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", \"ML_METHOD\": \"#f6c5be\"}}\n",
    "displacy.render(doc, style=\"ent\", options=options, jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27735c14-b2a0-4c2c-880f-d7a392348409",
   "metadata": {},
   "source": [
    "Lets only select sentences with a ML_METHOD entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d072f8a-d143-47dd-bf9f-0c78ef34a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentences:\n",
      "Linear regression\n",
      "Daniel Hsu (COMS 4771)\n",
      "Maximum likelihood estimation\n",
      "One of the simplest linear regression models is the following: (X1,Y1),..., (Xn,Yn),(X,Y)are iid random\n",
      "pairs taking values in Rd×R, and\n",
      "Y|X=x∼N(xTw,σ2),x∈Rd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract sentences with ML_METHOD entities\n",
    "filtered_sentences = [\n",
    "    sentence.text\n",
    "    for sentence in doc.sents\n",
    "    if any(ent.label_ == \"ML_METHOD\" for ent in sentence.ents)\n",
    "]\n",
    "\n",
    "# Create a new text containing only those sentences\n",
    "filtered_text = \" \".join(filtered_sentences)\n",
    "\n",
    "# Create a new Doc object with the filtered text\n",
    "filtered_doc = nlp(filtered_text)\n",
    "\n",
    "# Print the filtered sentences\n",
    "print(\"Filtered Sentences:\")\n",
    "for sentence in filtered_doc.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b10c9acd-b9c1-495b-b51d-1b3a3505145b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Linear regression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ML_METHOD</span>\n",
       "</mark>\n",
       "<br>Daniel Hsu (COMS 4771)<br>Maximum likelihood estimation<br>One of the simplest \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    linear regression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ML_METHOD</span>\n",
       "</mark>\n",
       " models is the following: (X1,Y1),..., (Xn,Yn),(X,Y)are iid random<br>pairs taking values in Rd×R, and<br>Y|X=x∼N(xTw,σ2),x∈Rd.<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displacy.render(filtered_doc, style=\"ent\", jupyter=True)  # Use jupyter=True if in a notebook\n",
    "\n",
    "options = {\"colors\": {\"ML_METHOD\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}}\n",
    "displacy.render(filtered_doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b649f4-54a1-4925-afad-69bb57e00b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
